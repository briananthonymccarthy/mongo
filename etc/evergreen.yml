#####################################################
#               A note on expansions                #
#####################################################

# Expansions usually appear in the form ${key|default}
# If 'key' is found in the executor's map of currently known
# expansions, the corresponding value is used. If the key can
# not be found, the default is used.
#
# Arbitrary expansions can be specified in the YAML configuration
# files in the following places:
# - The 'expansions' field for buildvariants (branch file)
# - The 'expansions' field for distros (distros file)
#
# A number of 'built-in' expansions are also available for use; these include:
# - environment variables available on the host machine
# - 'workdir' (references the executor's work directory).
# - 'task_id' (references the task id of the task the executor is working on).
# - 'build_variant' (references the executing task's buildvariant).
# - 'config_root' (references the root directory for the executor's configuration artifacts).

stepback: true
command_type: system

# Files that match an ignore-list pattern will not trigger a build, if they're the only modified
# files in the patch.
ignore:
  - ".*"
  - "!.clang-format"
  - "!.eslintrc.yml"
  - "*.md"
  - "*.rst"
  - "*.txt"
  - "/distsrc/**"
  - "/docs/**"
  - "/etc/*.yml"
  - "!/etc/evergreen.yml"
  - "README"

## Some variables for convenience:
variables:

# Used when the tests it runs depend only on mongod, mongos, the mongo shell and the tools.
- &task_template
  name: template
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --help
      resmoke_jobs_max: 0  # No cap on number of jobs.

# Used for tests that invoke resmoke.py and require no additional setup.
- &task_depending_on_all_template
  <<: *task_template
  depends_on:
  - name: compile_all

- &benchmark_template
  name: benchmark_template
  depends_on:
  - name: compile_benchmarks
  commands:
  - func: "do benchmark setup"
  - func: "run tests"
    vars:
      resmoke_args: --help
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- &benchrun_embedded_template
  name: benchrun_embedded_template
  depends_on:
  - generate_benchrun_embedded_files
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --help
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- &jepsen_config_vars
  jepsen_key_time_limit: --key-time-limit 15
  jepsen_protocol_version: --protocol-version 1
  jepsen_read_concern: ""
  jepsen_read_with_find_and_modify: ""
  jepsen_storage_engine: ""
  jepsen_test_name: ""
  # Empirically, we've had greater success in reproducing the issues found in MongoDB versions
  # 3.4.0-rc3 and 3.4.0-rc4 when running Jepsen with at least --time-limit=600.
  jepsen_time_limit: --time-limit 1200
  jepsen_write_concern: ""

# Template for running Jepsen tests
- &run_jepsen_template
  name: run_jepsen_template
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "do jepsen setup"
  - func: "run jepsen test"
    vars:
      <<: *jepsen_config_vars

- &jstestfuzz_config_vars
  num_files: 15
  num_tasks: 10
  resmoke_args: --help # resmoke_args needs to be overridden to specify one of the jstestfuzz suites
  resmoke_jobs_max: 1
  should_shuffle: false
  continue_on_failure: false
  # Terminate the function when there has been no output to stdout for 30 minutes. E.g. when something is stuck in an infinite loop.
  # resmoke.py writes the test output to logkeeper and only writes to stdout when starting the next test.
  # resmoke.py not producing output on stdout means that the test is still running and presumably not going to finish.
  # Note that timeout_secs is different from exec_timeout_secs, which applies to a task and times out regardless of whether output has been written to stdout.
  timeout_secs: 1800

# Used for tests that invoke 'resmoke.py --suites=jstestfuzz*'.
- &jstestfuzz_template
  name: jstestfuzz_template
  exec_timeout_secs: 14400 # Time out the task if it runs for more than 4 hours.
  depends_on: []
  commands:
  - func: "generate fuzzer tasks"

# Templates used by powercycle
- &powercycle_remote_credentials
  private_key_file: $(${posix_workdir})/powercycle.pem
  private_key_remote: ${powercycle_private_key}
  aws_key_remote: ${powercycle_aws_key}
  aws_secret_remote: ${powercycle_aws_secret}

- &powercycle_ec2_instance
  aws_ec2_yml: aws_ec2.yml
  ec2_expire_hours: "24"
  ec2_monitor_files: proc.json system.json
  monitor_proc_file: proc.json
  monitor_system_file: system.json
  remote_dir: /log/powercycle
  secret_port: "20001"
  security_group_ids: ${powercycle_aws_security_group_id}
  security_groups: mci powercycle_testing
  subnet_id: ${powercycle_aws_subnet_id}
  ssh_identity: -i ${private_key_file}
  ssh_key_id: ${powercycle_ssh_key_id}
  standard_port: "20000"
  virtualenv_dir: venv_powercycle
  windows_crash_cmd: \"notmyfault/notmyfaultc64.exe -accepteula crash 1\"
  windows_crash_dl: https://download.sysinternals.com/files/NotMyFault.zip
  windows_crash_dir: notmyfault
  windows_crash_zip: notmyfault.zip

- &powercycle_expansions
  params:
     updates:
     - key: backup_path_after
       value: ${remote_dir}/afterrecovery
     - key: backup_path_before
       value: ${remote_dir}/beforerecovery
     - key: backup_artifacts
       value: ${remote_dir}/afterrecovery* ${remote_dir}/beforerecovery*
     - key: db_path
       value: /data/db
     - key: log_path
       value: ${remote_dir}/mongod.log
     - key: exit_file
       value: powercycle_exit.yml

- &powercycle_test
  ec2_artifacts: ${log_path} ${db_path} ${backup_artifacts}
  program_options:  --exitYamlFile=${exit_file} --logLevel=info --backupPathBefore=${backup_path_before} --backupPathAfter=${backup_path_after}
  connection_options: --sshUserHost=${private_ip_address} --sshConnection=\"${ssh_identity} ${ssh_connection_options}\"
  test_options: --testLoops=15 --seedDocNum=10000 --rsync --rsyncExcludeFiles=diagnostic.data/metrics.interim* --validate=local --canary=local
  crash_options: --crashMethod=internal --crashOption=${windows_crash_cmd} --crashWaitTime=45 --jitterForCrashWaitTime=5 --instanceId=${instance_id}
  client_options: --numCrudClients=20 --numFsmClients=20
  mongodb_options: --rootDir=${remote_dir}-${task_id} --mongodbBinDir=${remote_dir}
  mongod_options: --mongodUsablePorts ${standard_port} ${secret_port} --dbPath=${db_path} --logPath=${log_path}
  mongod_extra_options: --mongodOptions=\"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}'\"

- &benchrun_embedded
  name: benchrun_embedded
  execution_tasks:
  - benchrun_embedded_aggregation
  - benchrun_embedded_commands
  - benchrun_embedded_insert
  - benchrun_embedded_misc
  - benchrun_embedded_mixed_and_multi
  - benchrun_embedded_queries
  - benchrun_embedded_remove
  - benchrun_embedded_update
  - generate_benchrun_embedded_files

- &unittests
  name: unittests!
  execution_tasks:
  - compile_unittests
  - unittests

- &dbtest
  name: dbtest!
  execution_tasks:
  - compile_dbtest
  - dbtest

- &compile_task_group_template
  name: compile_task_group_template
  max_hosts: 1
  tasks: []
  setup_task:
  - func: "apply compile expansions"
  - func: "set task expansion macros"
  teardown_task:
  - func: "attach scons config log"
  - func: "attach report"
  - func: "attach artifacts"
  - func: "kill processes"
  - func: "save code coverage data"
  - func: "save mongo coredumps"
  - func: "save failed unittests"
  - func: "save unstripped dbtest"
  - func: "save hang analyzer debugger files"
  - func: "save disk statistics"
  - func: "save system resource information"
  - func: "remove files"
    vars:
      files: >-
        src/resmoke_error_code
        src/build/scons/config.log
        src/*.gcda.gcov
        src/gcov-intermediate-files.tgz
        src/*.core src/*.mdmp
        mongo-coredumps.tgz
        src/unittest_binaries/*_test${exe}
        mongo-unittests.tgz
        src/debugger*.*
        src/mongo-hanganalyzer.tgz
        diskstats.tgz
        system-resource-info.tgz
        ${report_file|src/report.json}
        ${archive_file|src/archive.json}
  setup_group:
  - func: "kill processes"
  - func: "cleanup environment"
  # The python virtual environment is installed in ${workdir}, which is created in
  # "set up virtualenv".
  - func: "set up virtualenv"
  - func: "set task expansion macros"
  - func: "clear OOM messages"
  - command: manifest.load
  - func: "git get project"
  - func: "get modified patch files"
  # NOTE: To disable the compile bypass feature, comment out the next line.
  #
  - func: "bypass compile and fetch binaries"
  - func: "update bypass expansions"
  - func: "get buildnumber"
  - func: "set up credentials"
  - func: "fetch and build OpenSSL"
  - func: "use WiredTiger develop" # noop if ${use_wt_develop} is not "true"
  - func: "install pip requirements"
  - func: "generate compile expansions"
  teardown_group:
  - func: "scons cache pruning"
  - func: "umount shared scons directory"
  - func: "print OOM messages"
  - func: "cleanup environment"
  timeout:
  - func: "run hang analyzer"

# Use this template for enterprise Windows testing coverage on non-pushing
# variants
- &enterprise-windows-64-2k8-nopush-template
  name: enterprise-windows-64-2k8-nopush-template
  run_on:
  - windows-64-vs2017-test
  modules:
  - enterprise
  display_tasks:
  - *dbtest
  - *unittests
  expansions: &enterprise-windows-64-2k8-nopush-expansions-template
    platform_decompress: unzip
    exe: ".exe"
    msi_target: msi
    content_type: application/zip
    compile_flags: --release --ssl MONGO_DISTMOD=windows-64 CPPPATH="c:/sasl/include c:/snmp/include" LIBPATH="c:/sasl/lib c:/snmp/lib" -j$(( $(grep -c ^processor /proc/cpuinfo) / 2 )) --dynamic-windows --win-version-min=ws08r2
    # We invoke SCons using --jobs = (# of CPUs / 4) to avoid causing out of memory errors due to
    # spawning a large number of linker processes.
    num_scons_link_jobs_available: $(( $(grep -c ^processor /proc/cpuinfo) / 4 ))
    python: python
    python3: '/cygdrive/c/python/python36/python.exe'
    ext: zip
    use_scons_cache: true
    multiversion_platform: windows
    multiversion_edition: enterprise
    tooltags: "ssl sasl"
    build_mongoreplay: false
    jstestfuzz_num_generated_files: 35
    large_distro_name: windows-64-vs2017-compile
  tasks:
  - name: compile_all_run_unittests_TG
    requires:
    - name: burn_in_tests
    distros:
    - windows-64-vs2017-compile
  - name: compile_benchmarks
    distros:
    - windows-64-vs2017-compile
  - name: burn_in_tests
  - name: aggregation_multiversion_fuzzer_gen
  - name: aggregation_wildcard_fuzzer_gen
  - name: audit
  - name: auth_audit_gen
  - name: benchmarks_orphaned
  - name: benchmarks_sharding
  - name: buildscripts_test
  - name: ese
  - name: external_auth
    distros:
    - windows-64-2016
  - name: fle
  - name: jsCore
  - name: jsCore_ese
  - name: jsCore_decimal
  - name: jsCore_auth
  - name: jsCore_txns
  - name: causally_consistent_jscore_txns_passthrough
  - name: jstestfuzz_gen
  - name: jstestfuzz_concurrent_gen
  - name: jstestfuzz_concurrent_replication_gen
  - name: jstestfuzz_concurrent_sharded_gen
  - name: jstestfuzz_replication_gen
  - name: jstestfuzz_sharded_gen
  - name: logical_session_cache_replication_100ms_refresh_jscore_passthrough_gen
  - name: logical_session_cache_replication_1sec_refresh_jscore_passthrough_gen
  - name: logical_session_cache_replication_10sec_refresh_jscore_passthrough_gen
  - name: logical_session_cache_replication_default_refresh_jscore_passthrough_gen
  - name: logical_session_cache_sharding_100ms_refresh_jscore_passthrough_gen
  - name: logical_session_cache_sharding_1sec_refresh_jscore_passthrough_gen
  - name: logical_session_cache_sharding_10sec_refresh_jscore_passthrough_gen
  - name: logical_session_cache_sharding_default_refresh_jscore_passthrough_gen
  - name: logical_session_cache_standalone_100ms_refresh_jscore_passthrough_gen
  - name: logical_session_cache_standalone_1sec_refresh_jscore_passthrough_gen
  - name: logical_session_cache_standalone_10sec_refresh_jscore_passthrough_gen
  - name: logical_session_cache_standalone_default_refresh_jscore_passthrough_gen
  - name: replica_sets_auth_gen
  - name: replica_sets_ese_gen
  - name: sasl
  - name: sharding_auth_gen
  - name: sharding_auth_audit_gen
  - name: sharding_ese_gen
  - name: snmp
  - name: ssl_gen
  - name: sslSpecial_gen

- &stitch_support_task_group_template
  name: stitch_support_task_group_template
  setup_task:
    - func: "apply compile expansions"
    - func: "set task expansion macros"
  teardown_task:
  setup_group:
    - func: "kill processes"
    - func: "cleanup environment"
    - func: "set up virtualenv"
    - command: manifest.load
    - func: "set task expansion macros"
    - func: "git get project"
    - func: "get buildnumber"
    - func: "install pip requirements"
    - func: "generate compile expansions"
  teardown_group:
    - func: "scons cache pruning"
    - func: "umount shared scons directory"

#######################################
#            Functions                #
#######################################

functions:

  "remove files": &remove_files
    command: shell.exec
    params:
      script: |
        if [ -z "${files}" ]; then
          exit 0
        fi
        for file in ${files}
        do
          if [ -f "$file" ]; then
            echo "Removing file $file"
            rm -f $file
          fi
        done

  "configure evergreen api credentials" : &configure_evergreen_api_credentials
    command: shell.exec
    type: test
    params:
      working_dir: src
      silent: true
      script: |
        # Create the Evergreen API credentials
        cat > .evergreen.yml <<END_OF_CREDS
        api_server_host: https://evergreen.mongodb.com/api
        api_key: "${evergreen_api_key}"
        user: "${evergreen_api_user}"
        END_OF_CREDS

  "git get project" : &git_get_project
    command: git.get_project
    params:
      directory: ${git_project_directory|src}
      revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
        enterprise: ${enterprise_rev}
        wtdevelop: ${wtdevelop_rev}

  "fetch artifacts" : &fetch_artifacts
    command: s3.get
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      remote_file: ${project}/${build_variant}/${revision}/artifacts/${build_id}.tgz
      bucket: mciuploads
      extract_to: src

  "fetch binaries" : &fetch_binaries
    command: s3.get
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      remote_file: ${mongo_binaries}
      bucket: mciuploads
      local_file: src/mongo-binaries.tgz

  "extract binaries" : &extract_binaries
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        ${decompress} mongo-binaries.tgz
        cp mongodb*/bin/* .

  "check binary version" : &check_binary_version
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        mongo_binary=$(find mongodb*/bin -name mongo${exe})
        # There should only be one mongo shell
        if [ $(echo $mongo_binary | wc -w) -ne 1 ]; then
          echo "There is more than 1 extracted mongo binary: $mongo_binary"
          exit 1
        fi
        # For compile bypass we need to skip the binary version check since we can tag a commit
        # after the base commit binaries were created. This would lead to a mismatch of the binaries
        # and the version from git describe in the compile_expansions.yml.
        if [ "${is_patch}" = "true" ] && [ "${bypass_compile|false}" = "true" ]; then
          echo "Skipping binary version check since we are bypassing compile in this patch build."
          exit 0
        fi
        ${activate_virtualenv}
        $python -m pip install -r etc/pip/evgtest-requirements.txt
        bin_ver=$($python -c "import yaml; print(yaml.safe_load(open('compile_expansions.yml'))['version']);" | tr -d '[ \r\n]')
        # Due to SERVER-23810, we cannot use $mongo_binary --quiet --nodb --eval "version();"
        mongo_ver=$($mongo_binary --version | perl -pe '/version v(.*)$/; $_ = $1;' | tr -d '[ \r\n]')
        # The versions must match
        if [ "$bin_ver" != "$mongo_ver" ]; then
          echo "The mongo version is $mongo_ver, expected version is $bin_ver"
          exit 1
        fi

  "fetch benchmarks" : &fetch_benchmarks
    command: s3.get
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      remote_file: ${project}/${build_variant}/${revision}/benchmarks/${build_id}.tgz
      bucket: mciuploads
      extract_to: src

  "fetch benchrun embedded files" : &fetch_benchrun_embedded_files
    command: s3.get
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      remote_file: ${project}/${build_variant}/${revision}/benchrun_json_files.tgz
      bucket: mciuploads
      extract_to: src/benchrun_embedded/testcases

  "get buildnumber" : &get_buildnumber
    command: keyval.inc
    params:
      key: "${build_variant}_master"
      destination: "builder_num"

  "run diskstats": &run_diskstats
    command: shell.exec
    params:
      background: true
      system_log: true
      script: |
        set -o errexit
        set -o verbose

        # On Windows we can use typeperf.exe to dump performance counters.
        if [ "Windows_NT" = "$OS" ]; then
            typeperf -qx PhysicalDisk | grep Disk | grep -v _Total > disk_counters.txt
            typeperf -cf disk_counters.txt -si 5 -o mongo-diskstats
        # Linux: iostat -t option for timestamp.
        elif iostat -tdmx > /dev/null 2>&1; then
            iostat -tdmx 5 > mongo-diskstats
        # OSX: Simulate the iostat timestamp.
        elif iostat -d > /dev/null 2>&1; then
            iostat -d -w 5 | while IFS= read -r line; do printf '%s %s\n' "$(date +'%m/%d/%Y %H:%M:%S')" "$line" >> mongo-diskstats; done
        # Check if vmstat -t is available.
        elif vmstat -td  > /dev/null 2>&1; then
            vmstat -td 5 > mongo-diskstats
        # Check if vmstat -T d is available.
        elif vmstat -T d > /dev/null 2>&1; then
            vmstat -T d 5 > mongo-diskstats
        else
            printf "Cannot collect mongo-diskstats on this platform\n"
        fi

  "collect system resource info": &collect_system_resource_info
    command: shell.exec
    params:
      working_dir: src
      background: true
      system_log: true
      script: |
        ${activate_virtualenv}
        $python buildscripts/collect_resource_info.py -o system_resource_info.json -i 5

  # Run a monitor process as a background, system task to periodically
  # display how many threads interesting processes are using.
  "monitor process threads": &monitor_process_threads
    command: shell.exec
    params:
      background: true
      system_log: true
      script: |
        proc_list="(bsondump|java|lein|mongo|python|_test$|_test\.exe$)"
        if [ "Windows_NT" = "$OS" ]; then
          get_pids() {
            proc_pids=$(tasklist /fo:csv |
                        awk -F'","' '{x=$1; gsub("\"","",x); print $2, x}' |
                        grep -iE $1 |
                        cut -f1 -d ' ');
          }
          get_process_info() {
            proc_name="";
            proc_info=$(wmic process where "ProcessId=\"$1\"" get "Name,ProcessId,ThreadCount" /format:csv 2> /dev/null | grep $1);
            if [ ! -z $proc_info ]; then
              proc_name=$(echo $proc_info | cut -f2 -d ',');
              proc_threads=$(echo $proc_info | cut -f4 -d ',');
            fi;
          }
        else
          get_pids() { proc_pids=$(pgrep $1); }
          get_process_info() {
            proc_name=$(ps -p $1 -o comm=);
            # /proc is available on Linux platforms
            if [ -f /proc/$1/status ]; then
              ${set_sudo}
              proc_threads=$($sudo grep Threads /proc/$1/status | sed "s/\s//g" | cut -f2 -d ":");
            else
              proc_threads=$(ps -AM $1 | grep -vc PID);
            fi;
          }
        fi
        while [ 1 ]
        do
          get_pids $proc_list
          if [ ! -z "$proc_pids" ]; then
            printf "Running process/thread counter\n"
            printf "PROCESS\tPID\tTHREADS\n"
          fi
          for pid in $proc_pids
          do
            get_process_info $pid
            if [ ! -z "$proc_name" ]; then
              printf "$proc_name\t$pid\t$proc_threads\n"
            fi
          done
          sleep 60
        done

  "set up credentials" : &set_up_credentials
    command: shell.exec
    params:
      working_dir: src
      silent: true
      script: |
        cat > mci.buildlogger <<END_OF_CREDS
        slavename='${slave}'
        passwd='${passwd}'
        builder='MCI_${build_variant}'
        build_num=${builder_num}
        build_phase='${task_name}_${execution}'
        END_OF_CREDS

  "set up notary client credentials" : &set_up_notary_client_credentials
    command: shell.exec
    params:
      working_dir: src
      silent: true
      script: |
        set -o errexit

        cat <<EOF > notary_env.sh
        export NOTARY_TOKEN=${signing_auth_token_42}
        EOF

        echo "${signing_auth_token_42}" > signing_auth_token

  "set up remote credentials": &set_up_remote_credentials
    command: shell.exec
    params:
      silent: true
      script: |
        set -o errexit

        # Since the macros 'private_key_remote' and 'private_key_file' are not always defined
        # we default to /dev/null to avoid syntax errors of an empty expansion.
        if [ ! -z "${private_key_remote}" ] && [ ! -z "${private_key_file}" ] ; then
          mkdir -p ~/.ssh
          echo -n "${private_key_remote}" > ${private_key_file|/dev/null}
          chmod 0600 ${private_key_file|/dev/null}
        fi

        if [ ! -d ~.aws ]; then
          mkdir -p ~/.aws
        fi

        # If ${aws_profile_remote} is not specified then the config & credentials are
        # stored in the 'default' profile.
        aws_profile="${aws_profile_remote|default}"

        # The profile in the config file is specified as [profile <profile>], except
        # for [default], see http://boto3.readthedocs.io/en/latest/guide/configuration.html
        if [ $aws_profile = "default" ] ; then
          aws_profile_config="[default]"
        else
          aws_profile_config="[profile $aws_profile]"
        fi
        cat <<EOF >> ~/.aws/config
        $aws_profile_config
        region = us-east-1
        EOF

        # The profile in the credentials file is specified as [<profile>].
        cat <<EOF >> ~/.aws/credentials
        [$aws_profile]
        aws_access_key_id = ${aws_key_remote}
        aws_secret_access_key = ${aws_secret_remote}
        EOF

        cat <<EOF > ~/.boto
        [Boto]
        https_validate_certificates = False
        EOF

  "call BF Suggestion service":
    command: shell.exec
    params:
      working_dir: src
      shell: bash
      silent: true
      script: |
        report_file="report.json"
        # Check if the report file exists and has failures.
        if [ -f $report_file ] && grep -Eq "\"failures\": [1-9]" $report_file; then
          # Calling the BF Suggestion server endpoint to start feature extraction.
          payload="{\"task_id\": \"${task_id}\", \"execution\": ${execution}}"
          echo "Sending task info to the BF suggestion service"
          # The --user option is passed through stdin to avoid showing in process list.
          user_option="--user ${bfsuggestion_user}:${bfsuggestion_password}"
          curl --header "Content-Type: application/json" \
               --data "$payload" \
               --max-time 10 \
               --silent \
               --show-error \
               --config - \
               https://bfsuggestion.corp.mongodb.com/tasks <<< $user_option
          echo "Request to BF Suggestion service status: $?"
        fi

  "upload debugsymbols" : &upload_debugsymbols
    command: s3.put
    params:
      optional: true
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/mongo-debugsymbols.tgz
      remote_file: ${mongo_debugsymbols}
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}

  "fetch debugsymbols archive" : &fetch_debugsymbols_archive
    command: s3.get
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      remote_file: ${mongo_debugsymbols}
      bucket: mciuploads
      local_file: src/mongo-debugsymbols.tgz

  "extract debugsymbols" : &extract_debugsymbols
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose
        # Debug symbols are not created for every variant
        if [ ! -f mongo-debugsymbols.tgz ]; then
          exit
        fi
        ${decompress} mongo-debugsymbols.tgz
        files="mongo mongod mongos"
        file_exts="debug dSYM pdb"
        for file_ext in $file_exts
        do
            for file in $files
            do
                mv mongodb*/$file.$file_ext . 2>/dev/null || true
            done
            rm -r mongodb*/*.$file_ext 2>/dev/null || true
        done
        rm mongo-debugsymbols.tgz 2>/dev/null || true

  "fetch and build OpenSSL" :
    command: shell.exec
    params:
        working_dir:  src
        script: |
            set -o errexit
            set -o verbose
            if [ "${build_openssl|}" = "true" ]; then
                bash buildscripts/fetch_and_build_openssl.sh "${python|python}" "${openssl_make_flags|}" "${openssl_config_flags|}"
            fi

  "use WiredTiger develop" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose
        if [ "${use_wt_develop|}" = "true" ]; then
        cd src/third_party
        for wtdir in api dist examples ext lang src test tools ; do
          rm -rf wiredtiger/$wtdir
          mv wtdevelop/$wtdir wiredtiger/
        done
        fi

  "setup gradle signing keys":
    command: shell.exec
    params:
      silent: true
      shell: bash
      script: |
        cd src/src/mongo/embedded/mongo_embedded/java

        echo '${mongodb_mobile_release_secring}' | base64 -d > embedded-android/secring.gpg

        cat <<EOF > local.properties
        signing.keyId=${mongodb_mobile_release_signing_keyid}
        signing.password=${mongodb_mobile_release_signing_password}
        signing.secretKeyRingFile=${mongodb_mobile_release_signing_secretkeyringfile}

        ossrhUsername=${mongodb_mobile_ossrh_username}
        ossrhPassword=${mongodb_mobile_ossrh_password}
        EOF

        cat <<EOF > artifactory_mobile_creds.sh
        export artifactory_mobile_user=${artifactory_mobile_user}
        export artifactory_mobile_pass=${artifactory_mobile_pass}
        EOF

  "setup android toolchain" :
    command: shell.exec
    params:
      script: |
        set -o errexit
        set -o verbose
        if [ "${setup_android_toolchain|}" = "true" ]; then
            ${activate_virtualenv}
            PYTHON=$python ${compile_env|} src/buildscripts/setup-android-toolchain.sh ${android_toolchain_target_arch} ${android_toolchain_api_version}
        fi

  "build java embedded sdk":
    command: shell.exec
    params:
      shell: bash
      script: |
        set -o errexit
        set -o verbose

        # If the android toolchain has not been setup the android sdk will not
        # be available and we should not build the android version of mongodb
        # embedded.
        if [ "${setup_android_toolchain|}" = "true" ]; then
            export ANDROID_HOME=$(pwd)/android_sdk

            cd src/src/mongo/embedded/mongo_embedded/java

            # TODO: Clean this up later where we can remove duplication
            if [ ${package_type|embedded-android} = "embedded-jar" ]; then
                tar zxvf ../../../../../../embedded-sdk-java-linux-x86-64.tgz
                mkdir -p jniLibs/linux-x86-64
                cp ./mongo-embedded-sdk-${version}/lib/libmongo_embedded.so jniLibs/linux-x86-64
                rm -rf ./mongo-embedded-sdk-${version}

                tar zxvf ../../../../../../embedded-sdk-java-darwin.tgz
                mkdir -p jniLibs/darwin
                cp ./mongo-embedded-sdk-${version}/lib/libmongo_embedded.dylib jniLibs/darwin
                rm -rf ./mongo-embedded-sdk-${version}

                ./gradlew clean :embedded-jar:build :embedded-jar:publishMavenPublicationToLocalRepository

                # Is this a release?
                if [ "${is_release|false}" = "true" ]; then
                    echo "Releases disabled on master."
                    #source ./artifactory_mobile_creds.sh
                    #./gradlew --info :embedded-jar:artifactoryPublish
                fi


                mkdir -p ../../../../../build/mongo-embedded-sdk-${version}/java
                cp -r embedded-jar/build/repo/* ../../../../../build/mongo-embedded-sdk-${version}/java
            else
                for arch in arm64-v8a armeabi-v7a x86_64 ; do
                    tar zxvf ../../../../../../embedded-sdk-android-$arch.tgz
                    mkdir -p jniLibs/$arch
                    cp ./mongo-embedded-sdk-${version}/lib/libmongo_embedded.so jniLibs/$arch
                    rm -rf ./mongo-embedded-sdk-${version}
                done

                ./gradlew clean :embedded-android:build
                # Is this a release?
                if [ "${is_release|false}" = "true" ]; then
                    echo "Releases disabled on master."
                    #./gradlew :embedded-android:uploadArchives closeAndReleaseRepository
                fi

                mkdir -p ../../../../../build/mongo-embedded-sdk-${version}/android
                cp -r embedded-android/build/repo/* ../../../../../build/mongo-embedded-sdk-${version}/android
            fi
        fi

  "shared scons cache pruning" :
    command: shell.exec
    type: system
    params:
      shell: bash
      working_dir: src
      script: |
        set -o errexit
        set -o verbose
        # removes files from the shared scons cache.

        # Only prune on master branch
        if [[ "${project}" == "mongodb-mongo-master" ]]; then


          set +o errexit
          mount | grep "\/efs" > /dev/null
          if [ $? -eq 0 ]; then
            echo "Shared cache is already mounted"
          else
            echo "Shared cache - mounting file system"
            sudo mount /efs
          fi
          set -o errexit

          dirs=$(ls -l /efs | grep -v total | awk '{print $NF}')

          echo "Pruning shared SCons directories"

          for dir in $dirs; do
            echo "Pruning /efs/$dir/scons-cache"

            if [ -e /efs/$dir/info/distro_name ]; then
              distro=$(cat /efs/$dir/info/distro_name)
            fi

            # Set cache sizes by distro
            case $distro in
                 ubuntu1604|ubuntu1804|rhel62|rhel70)
                      cache_size=600
                      ;;
                 *)
                      # default
                      cache_size=400
                      ;;
            esac

            sudo python buildscripts/scons_cache_prune.py --cache-dir /efs/$dir/scons-cache --cache-size $cache_size --prune-ratio 1.0
            echo ""
          done

          sudo umount /efs || true

        else
          echo "Not on master, shared SCons cache pruning skipped"
        fi

  "scons cache pruning" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose
        # removes files from the local scons cache.

        ${activate_virtualenv}
        echo "Legacy local shared cache prune"
        if [ -d "${scons_cache_path}" ]; then
          $python buildscripts/scons_cache_prune.py --cache-dir ${scons_cache_path} --cache-size ${scons_cache_size|200} --prune-ratio ${scons_prune_ratio|0.8}
        fi

  "umount shared scons directory" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        if [ "${scons_cache_scope}" = "shared" ]; then
            ${set_sudo}
            $sudo umount /efs || true
        fi

  "build new tools" :
    command: shell.exec
    params:
      working_dir: src/src/mongo/gotools/src/github.com/mongodb/mongo-tools
      script: |
        set -o verbose
        set -o errexit

        # make sure newlines in the scripts are handled correctly by windows
        if [ "Windows_NT" = "$OS" ]; then
            set -o igncr
        fi;

        # set_goenv provides set_goenv(), print_ldflags() and print_tags() used below
        . ./set_goenv.sh
        GOROOT="" set_goenv || exit
        env | grep ^GO
        go version

        build_tools="bsondump mongostat mongofiles mongoexport mongoimport mongorestore mongodump mongotop"

        if [ "${build_mongoreplay}" = "true" ]; then
            build_tools="$build_tools mongoreplay"
        fi

        for i in $build_tools; do
            go build -ldflags "$(print_ldflags)" ${args} -tags "$(print_tags ${tooltags})" -o "../../../../../../mongo-tools/$i${exe|}" $i/main/$i.go
            "../../../../../../mongo-tools/$i${exe|}" --version
        done

  "get modified patch files" :
    command: shell.exec
    params:
      working_dir: src
      shell: bash
      script: |
        set -o verbose
        set -o errexit

        # For patch builds gather the modified patch files.
        if [ "${is_patch}" = "true" ]; then
          # Get list of patched files
          git diff HEAD --name-only >> patch_files.txt
          if [ -d src/mongo/db/modules/enterprise ]; then
            pushd src/mongo/db/modules/enterprise
            # Update the patch_files.txt in the mongo repo.
            git diff HEAD --name-only >> ~1/patch_files.txt
            popd
          fi
        fi

  "install pip requirements" : &install_pip_requirements
    command: shell.exec
    params:
      working_dir: src
      shell: bash
      script: |
        set -o verbose
        set -o errexit

        ${activate_virtualenv}
        python2 -m pip install -r etc/pip/evgtest-requirements.txt

  "determine resmoke jobs" : &determine_resmoke_jobs
    command: shell.exec
    params:
      working_dir: src
      shell: bash
      script: |
        set -o verbose
        set -o errexit

        ${activate_virtualenv}
        $python buildscripts/evergreen_resmoke_job_count.py \
          --taskName ${task_name}                           \
          --buildVariant ${build_variant}                   \
          --jobFactor ${resmoke_jobs_factor|1}              \
          --jobsMax ${resmoke_jobs_max|0}                   \
          --outFile resmoke_jobs_expansion.yml

  "update resmoke jobs expansions" : &update_resmoke_jobs_expansions
    command: expansions.update
    params:
      ignore_missing_file: true
      file: src/resmoke_jobs_expansion.yml

  "determine task timeout" : &determine_task_timeout
    command: shell.exec
    params:
      working_dir: src
      shell: bash
      script: |
        set -o verbose
        set -o errexit

        ${activate_virtualenv}
        $python buildscripts/evergreen_task_timeout.py \
          --task-name ${task_name}                     \
          --build-variant ${build_variant}             \
          --timeout ${timeout_secs|0}                  \
          --out-file task_timeout_expansions.yml

  "update task timeout expansions" : &update_task_timeout_expansions
    command: expansions.update
    params:
      ignore_missing_file: true
      file: src/task_timeout_expansions.yml

  "update task timeout" : &update_task_timeout
    command: timeout.update
    params:
      timeout_secs: ${timeout_secs}

  "update bypass expansions" : &update_bypass_expansions
    command: expansions.update
    params:
      ignore_missing_file: true
      file: src/bypass_compile_expansions.yml

  "bypass compile and fetch binaries" :
    command: shell.exec
    params:
      continue_on_err: true
      working_dir: src
      shell: bash
      script: |
        set -o verbose
        set -o errexit

        # For patch builds determine if we can bypass compile.
        if [[ "${is_patch}" = "true" && "${task_name}" = "compile" ]]; then
          ${activate_virtualenv}
          $python buildscripts/bypass_compile_and_fetch_binaries.py            \
            --project ${project}                                               \
            --buildVariant ${build_variant}                                    \
            --revision ${revision}                                             \
            --patchFile patch_files.txt                                        \
            --outFile bypass_compile_expansions.yml                            \
            --jsonArtifact artifacts.json
        fi

  "send benchmark results" :
    command: json.send
    params:
      name: perf
      file: src/perf.json

  "do setup" :
  - *fetch_artifacts
  - *update_bypass_expansions
  - *fetch_binaries
  - *extract_binaries
  - *check_binary_version
  - *get_buildnumber
  - *set_up_credentials
  - *run_diskstats
  - *monitor_process_threads
  - *collect_system_resource_info

  "do benchmark setup" :
  - *git_get_project
  - *update_bypass_expansions
  - *get_buildnumber
  - *set_up_credentials
  - *fetch_benchmarks

  "do benchmark embedded setup" :
  - *git_get_project
  - *fetch_artifacts
  - *get_buildnumber
  - *set_up_credentials
  - *fetch_benchrun_embedded_files

  "set up virtualenv" :
    command: shell.exec
    type: test
    params:
        shell: bash
        script: |
          # exit immediately if virtualenv is not found
          set -o errexit
          set -o verbose

          virtualenv_loc=$(which ${virtualenv|virtualenv})

          python2_loc=$(which ${python|/opt/mongodbtoolchain/v3/bin/python2})
          python3_loc=$(which ${python3|/opt/mongodbtoolchain/v3/bin/python3})
          venv2_dir="${workdir}/venv"
          venv3_dir="${workdir}/venv_3"
          if command -V cygpath; then
            # Sad note: We have to use the Windows path instead of the posix path here.
            # Otherwise, virtualenv may mistakenly resolve paths relative to c:\cygdrive.
            python2_loc=$(cygpath -w $python2_loc)
            python3_loc=$(cygpath -w $python3_loc)
            venv2_dir="$(cygpath -w "$venv2_dir")"
            venv3_dir="$(cygpath -w "$venv3_dir")"
          fi

          # Set up virtualenvs in ${workdir}
          "$virtualenv_loc" --python "$python2_loc" --system-site-packages "$venv2_dir"
          "$virtualenv_loc" --python "$python3_loc" --system-site-packages "$venv3_dir"

          # Link python2/python3 in the primary virtualenv bin dir
          export VIRTUAL_ENV_DISABLE_PROMPT=yes
          venv2_bin="$(dirname "$(cd "$venv2_dir"; . ./*/activate; which python)")"
          py2_exe="$(cd "$venv2_dir"; . ./*/activate; which python)"
          py3_exe="$(cd "$venv3_dir"; . ./*/activate; which python)"
          if [[ ! -f $venv2_bin/python2 ]]; then ln -sfv "$py2_exe" "$venv2_bin/python2"; fi
          if [[ ! -f $venv2_bin/python3 ]]; then ln -sfv "$py3_exe" "$venv2_bin/python3"; fi

  "execute resmoke tests" : &execute_resmoke_tests
    command: shell.exec
    type: test
    params:
      working_dir: src
      shell: bash
      script: |
        set -o errexit
        set -o verbose

        if [[ ${disable_unit_tests|false} = "false" && ! -f ${skip_tests|/dev/null} ]]; then

        # activate the virtualenv if it has been set up
        ${activate_virtualenv}

        # Set the TMPDIR environment variable to be a directory in the task's working
        # directory so that temporary files created by processes spawned by resmoke.py get
        # cleaned up after the task completes. This also ensures the spawned processes
        # aren't impacted by limited space in the mount point for the /tmp directory.
        export TMPDIR="${workdir}/tmp"
        mkdir -p $TMPDIR

        if [ -f /proc/self/coredump_filter ]; then
          # Set the shell process (and its children processes) to dump ELF headers (bit 4),
          # anonymous shared mappings (bit 1), and anonymous private mappings (bit 0).
          echo 0x13 > /proc/self/coredump_filter

          if [ -f /sbin/sysctl ]; then
            # Check that the core pattern is set explicitly on our distro image instead
            # of being the OS's default value. This ensures that coredump names are consistent
            # across distros and can be picked up by Evergreen.
            core_pattern=$(/sbin/sysctl -n "kernel.core_pattern")
            if [ "$core_pattern" = "dump_%e.%p.core" ]; then
              echo "Enabling coredumps"
              ulimit -c unlimited
            fi
          fi
        fi

        extra_args="$extra_args --jobs=${resmoke_jobs|1}"

        if [ ${should_shuffle|true} = true ]; then
          extra_args="$extra_args --shuffle"
        fi

        if [ ${continue_on_failure|true} = true ]; then
          extra_args="$extra_args --continueOnFailure"
        fi

        # We reduce the storage engine's cache size to reduce the likelihood of a mongod process
        # being killed by the OOM killer. The --storageEngineCacheSizeGB command line option is only
        # filled in with a default value here if one hasn't already been specified in the task's
        # definition or build variant's definition.
        set +o errexit
        echo "${resmoke_args} ${test_flags}" | grep -q storageEngineCacheSizeGB
        if [ $? -eq 1 ]; then
          echo "${resmoke_args} ${test_flags}" | grep -q "\-\-storageEngine=inMemory"
          if [ $? -eq 0 ]; then
            # We use a default of 4GB for the InMemory storage engine.
            extra_args="$extra_args --storageEngineCacheSizeGB=4"
          else
            # We use a default of 1GB for all other storage engines.
            extra_args="$extra_args --storageEngineCacheSizeGB=1"
          fi
        fi
        set -o errexit


        # Reduce the JSHeapLimit for the serial_run task task on Code Coverage builder variant.
        if [[ "${build_variant}" = "enterprise-rhel-62-64-bit-coverage" && "${task_name}" = "serial_run" ]]; then
          extra_args="$extra_args --mongodSetParameter {'jsHeapLimitMB':10}"
        fi

        path_value="$PATH"
        if [ ${variant_path_suffix} ]; then
          path_value="$path_value:${variant_path_suffix}"
        fi
        if [ ${task_path_suffix} ]; then
          path_value="$path_value:${task_path_suffix}"
        fi

        if [ "${is_patch}" = "true" ]; then
          extra_args="$extra_args --tagFile=etc/test_lifecycle.yml --patchBuild"
        else
          extra_args="$extra_args --tagFile=etc/test_retrial.yml"
        fi

        resmoke_cmd_args="${resmoke_args}"

        # The "resmoke_wrapper" expansion is used by the 'burn_in_tests' task to wrap the resmoke.py
        # invocation. It doesn't set any environment variables and should therefore come last in
        # this list of expansions.
        set +o errexit
        PATH="$path_value"                              \
            AWS_PROFILE=${aws_profile_remote}           \
            ${gcov_environment}                         \
            ${lang_environment}                         \
            ${san_options}                              \
            ${san_symbolizer}                           \
            ${snmp_config_path}                         \
            ${resmoke_wrapper}                          \
            $python buildscripts/evergreen_run_tests.py \
                $resmoke_cmd_args                       \
                $extra_args                             \
                ${test_flags}                           \
                --log=buildlogger                       \
                --staggerJobs=on                        \
                --buildId=${build_id}                   \
                --distroId=${distro_id}                 \
                --executionNumber=${execution}          \
                --projectName=${project}                \
                --gitRevision=${revision}               \
                --revisionOrderId=${revision_order_id}  \
                --taskId=${task_id}                     \
                --taskName=${task_name}                 \
                --variantName=${build_variant}          \
                --versionId=${version_id}               \
                --archiveFile=archive.json              \
                --reportFile=report.json                \
                --perfReportFile=perf.json
        resmoke_exit_code=$?
        set -o errexit

        # 74 is exit code for IOError on POSIX systems, which is raised when the machine is
        # shutting down.
        #
        # 75 is exit code resmoke.py uses when the log output would be incomplete due to failing
        # to communicate with logkeeper.
        if [[ $resmoke_exit_code = 74 || $resmoke_exit_code = 75 ]]; then
          echo $resmoke_exit_code > run_tests_infrastructure_failure
          exit 0
        elif [ $resmoke_exit_code != 0 ]; then
          # On failure save the resmoke exit code.
          echo $resmoke_exit_code > resmoke_error_code
        fi
        exit $resmoke_exit_code
        fi # end if [[ ${disable_unit_tests} && ! -f ${skip_tests|/dev/null} ]]

  "retrieve generated test configuration": &retrieve_generated_test_configuration
    command: s3.get
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      bucket: mciuploads
      remote_file: ${project}/${build_variant}/${revision}/generate_tasks/${task}_gen-${build_id}.tgz
      local_file: "generate_tasks_config.tgz"

  "extract generated test configuration": &extract_generated_test_configuration
    command: shell.exec
    type: test
    params:
      shell: bash
      script: |
        set -o verbose
        set -o errexit

        target_dir="src/generated_resmoke_config"
        mkdir -p $target_dir
        mv generate_tasks_config.tgz $target_dir

        cd $target_dir
        tar xzf generate_tasks_config.tgz

  "generate resmoke tasks":
    - *git_get_project
    - *configure_evergreen_api_credentials
    - command: expansions.write
      params:
        file: src/expansions.yml

    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          ${activate_virtualenv}
          $python -m pip install -r etc/pip/evgtest-requirements.txt
          $python buildscripts/evergreen_generate_resmoke_tasks.py --expansion-file expansions.yml

    - command: archive.targz_pack
      params:
        target: generate_tasks_config.tgz
        source_dir: src/generated_resmoke_config
        include:
          - "*"

    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: generate_tasks_config.tgz
        remote_file: ${project}/${build_variant}/${revision}/generate_tasks/${task_name}-${build_id}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/gzip}
        display_name: Generated Task Config - Execution ${execution}

    - command: generate.tasks
      params:
        files:
          - src/generated_resmoke_config/${task}.json

  "run generated tests" :
  - *install_pip_requirements
  - *retrieve_generated_test_configuration
  - *extract_generated_test_configuration
  - command: expansions.update
    params:
      updates:
      - key: aws_key_remote
        value: ${mongodatafiles_aws_key}
      - key: aws_profile_remote
        value: mongodata_aws
      - key: aws_secret_remote
        value: ${mongodatafiles_aws_secret}
  - *set_up_remote_credentials
  - *determine_resmoke_jobs
  - *update_resmoke_jobs_expansions
  - *execute_resmoke_tests
    # The existence of the "run_tests_infrastructure_failure" file indicates this failure isn't
    # directly actionable. We use type=setup rather than type=system or type=test for this command
    # because we don't intend for any human to look at this failure.
  - command: shell.exec
    type: setup
    params:
      working_dir: src
      script: |
        set -o verbose
        if [ -f run_tests_infrastructure_failure ]; then
          exit $(cat run_tests_infrastructure_failure)
        fi

  "run tests" :
    - *install_pip_requirements
    - *determine_task_timeout
    - *update_task_timeout_expansions
    - *update_task_timeout
    - command: expansions.update
      params:
        updates:
        - key: aws_key_remote
          value: ${mongodatafiles_aws_key}
        - key: aws_profile_remote
          value: mongodata_aws
        - key: aws_secret_remote
          value: ${mongodatafiles_aws_secret}
    - *set_up_remote_credentials
    - *determine_resmoke_jobs
    - *update_resmoke_jobs_expansions
    - *execute_resmoke_tests
      # The existence of the "run_tests_infrastructure_failure" file indicates this failure isn't
      # directly actionable. We use type=setup rather than type=system or type=test for this command
      # because we don't intend for any human to look at this failure.
    - command: shell.exec
      type: setup
      params:
        working_dir: src
        script: |
          set -o verbose
          if [ -f run_tests_infrastructure_failure ]; then
            exit $(cat run_tests_infrastructure_failure)
          fi

  "scons compile" :
    command: shell.exec
    type: test
    params:
      working_dir: src
      shell: bash
      script: |
        set -o errexit
        set -o verbose

        if [ "${is_patch}" = "true" ] && [ "${bypass_compile|false}" = "true" ]; then
          exit 0
        fi
        rm -rf ${install_directory|/data/mongo-install-directory}

        extra_args=""
        if [ -n "${num_scons_link_jobs_available|}" ]; then
          echo "Changing SCons to run with --jlink=${num_scons_link_jobs_available|}"
          extra_args="$extra_args --jlink=${num_scons_link_jobs_available|}"
        fi

        if [ "${scons_cache_scope|}" = "shared" ]; then
          extra_args="$extra_args --cache-debug=scons_cache.log"
        fi

        ${activate_virtualenv}

        python2 -m pip install -r ./etc/pip/compile-requirements.txt
        ${compile_env|} $python ./buildscripts/scons.py                                     \
            ${compile_flags|} ${task_compile_flags|} ${task_compile_flags_extra|}           \
            ${scons_cache_args|} $extra_args                                                \
            ${targets} ${additional_targets|} MONGO_VERSION=${version} || exit_status=$?
        # If compile fails we do not run any tests
        if [[ $exit_status -ne 0 ]]; then
          if [[ "${dump_scons_config_on_failure}" == true ]]; then
            echo "Dumping build/scons/config.log"
            cat build/scons/config.log
          fi
          touch ${skip_tests}
        fi
        exit $exit_status

  "generate compile expansions" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        # We get the raw version string (r1.2.3-45-gabcdef) from git
        MONGO_VERSION=$(git describe)
        # If this is a patch build, we add the patch version id to the version string so we know
        # this build was a patch, and which evergreen task it came from
        if [ "${is_patch}" = "true" ] && [ "${bypass_compile|false}" = "false" ]; then
          MONGO_VERSION="$MONGO_VERSION-patch-${version_id}"
        fi

        ${activate_virtualenv}
        # shared scons cache testing
        # if 'scons_cache_scope' enabled and project level 'disable_shared_scons_cache' is not true
        # 'scons_cache_scope' is set on a per variant basis
        # 'disable_shared_scons_cache' is set on a project level and applies to all variants

        # Shared - if scons_cache_scope is set, then use new shared scons cache settings
        if [ ! -z ${scons_cache_scope} ]; then

          if [ "${disable_shared_scons_cache}" = "true" ]; then

            echo "SCons Cache disabled. All shared scons settings will be ignored"
            scons_cache_scope=none

          else
            scons_cache_scope=${scons_cache_scope}
          fi

          if [ "$scons_cache_scope" = "shared" ]; then
            set +o errexit
            mount | grep "\/efs" > /dev/null
            if [ $? -eq 0 ]; then
              echo "Shared cache is already mounted"
            else
              echo "Shared cache - mounting file system"
              ${set_sudo}
              $sudo mount /efs
            fi
            set -o errexit
          fi

          echo "Shared Cache with setting: ${scons_cache_scope}"
          MONGO_VERSION=$MONGO_VERSION SCONS_CACHE_MODE=${scons_cache_mode|nolinked} SCONS_CACHE_SCOPE=$scons_cache_scope IS_PATCH=${is_patch} $python buildscripts/generate_compile_expansions_shared_cache.py --out compile_expansions.yml

        # Legacy Expansion generation
        else
          echo "Using legacy expansion generation"
          # Proceed with regular expansions generated
          # This script converts the generated version string into a sanitized version string for
          # use by scons and uploading artifacts as well as information about for the scons cache.
          MONGO_VERSION=$MONGO_VERSION SCONS_CACHE_MODE=${scons_cache_mode|nolinked} USE_SCONS_CACHE=${use_scons_cache|false} $python buildscripts/generate_compile_expansions.py --out compile_expansions.yml
        fi

  "apply compile expansions" :
    command: expansions.update
    params:
      file: src/compile_expansions.yml

  "do jepsen setup" :
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit

          # Build libfaketime. A version of libfaketime at least as new as v0.9.6-9-g75896bd is
          # required to use the FAKETIME_NO_CACHE and FAKETIME_TIMESTAMP_FILE environment variables.
          # Additionally, a version of libfaketime containing the changes mentioned in SERVER-29336
          # is required to avoid needing to use libfaketimeMT.so.1 and serializing all calls to
          # fake_clock_gettime() with a mutex.
          git clone --branch=for-jepsen --depth=1 git@github.com:10gen/libfaketime.git
          cd libfaketime
          branch=$(git symbolic-ref --short HEAD)
          commit=$(git show -s --pretty=format:"%h - %an, %ar: %s")
          echo "Git branch: $branch, commit: $commit"
          make PREFIX=$(pwd)/build/ LIBDIRNAME='.' install
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          git clone --branch=jepsen-mongodb-master --depth=1 git@github.com:10gen/jepsen.git jepsen-mongodb
          cd jepsen-mongodb
          branch=$(git symbolic-ref --short HEAD)
          commit=$(git show -s --pretty=format:"%h - %an, %ar: %s")
          echo "Git branch: $branch, commit: $commit"
          lein install
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          ${activate_virtualenv}
          $python -c 'import socket; num_nodes = 5; print("\n".join(["%s:%d" % (socket.gethostname(), port) for port in range(20000, 20000 + num_nodes)]))' > nodes.txt

  "run jepsen test" :
    - command: shell.exec
      type: test
      timeout_secs: 2700 # Timeout test if there is no output for more than 45 minutes.
      params:
        working_dir: src/jepsen-mongodb
        script: |
          set -o verbose

          # Set the TMPDIR environment variable to be a directory in the task's working
          # directory so that temporary files created by processes spawned by jepsen get
          # cleaned up after the task completes. This also ensures the spawned processes
          # aren't impacted by limited space in the mount point for the /tmp directory.
          # We also need to set the _JAVA_OPTIONS environment variable so that lein will
          # recognize this as the default temp directory.
          export TMPDIR="${workdir}/tmp"
          mkdir -p $TMPDIR
          export _JAVA_OPTIONS=-Djava.io.tmpdir=$TMPDIR

          start_time=$(date +%s)
          lein run test --test ${jepsen_test_name}                                           \
                        --mongodb-dir ../                                                    \
                        --working-dir ${workdir}/src/jepsen-workdir                          \
                        --clock-skew faketime                                                \
                        --libfaketime-path ${workdir}/src/libfaketime/build/libfaketime.so.1 \
                        --mongod-conf mongod_verbose.conf                                    \
                        --virtualization none                                                \
                        --nodes-file ../nodes.txt                                            \
                        ${jepsen_key_time_limit}                                             \
                        ${jepsen_protocol_version}                                           \
                        ${jepsen_read_concern}                                               \
                        ${jepsen_read_with_find_and_modify}                                  \
                        ${jepsen_storage_engine}                                             \
                        ${jepsen_time_limit}                                                 \
                        ${jepsen_write_concern}                                              \
                        2>&1                                                                 \
          | tee jepsen_${task_name}_${execution}.log
          end_time=$(date +%s)
          elapsed_secs=$((end_time-start_time))
          # Since we cannot use PIPESTATUS to get the exit code from the "lein run ..." pipe in dash shell,
          # we will check the output for success, failure or setup error. Note that 'grep' returns with exit code
          # 0 if it finds a match, and exit code 1 if no match is found.
          grep -q "Everything looks good" jepsen_${task_name}_${execution}.log
          grep_exit_code=$?
          if [ $grep_exit_code -eq 0 ]; then
            status='"pass"'
            failures=0
            final_exit_code=0
          else
            grep -q "Analysis invalid" jepsen_${task_name}_${execution}.log
            grep_exit_code=$?
            if [ $grep_exit_code -eq 0 ]; then
              status='"fail"'
              failures=1
              final_exit_code=1
            else
              # If the failure is due to setup, then this is considered a system failure.
              echo $grep_exit_code > jepsen_system_failure_${task_name}_${execution}
              exit 0
            fi
          fi
          # Create report.json
          echo "{\"failures\": $failures, \"results\": [{\"status\": $status, \"exit_code\": $final_exit_code, \"test_file\": \"${task_name}\", \"start\": $start_time, \"end\": $end_time, \"elapsed\": $elapsed_secs}]}" > ../report.json
          exit $final_exit_code
    - command: shell.exec
      params:
        working_dir: src/jepsen-mongodb
        script: |
          set -o verbose
          # Jepsen system failure if file exists.
          if [ -f jepsen_system_failure_${task_name}_${execution} ]; then
            exit $(cat jepsen_system_failure_${task_name}_${execution})
          fi

  "generate fuzzer tasks":
    - *git_get_project

    - command: expansions.write
      params:
        file: src/expansions.yml

    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          ${activate_virtualenv}
          $python -m pip install -r etc/pip/evgtest-requirements.txt
          $python buildscripts/evergreen_gen_fuzzer_tests.py --expansion-file expansions.yml

    - command: archive.targz_pack
      params:
        target: generate_tasks_config.tgz
        source_dir: src/generated_resmoke_config
        include:
          - "*"

    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: generate_tasks_config.tgz
        remote_file: ${project}/${build_variant}/${revision}/generate_tasks/${task_id}-${execution}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/gzip}
        display_name: Generated Task Config - Execution ${execution}

    - command: generate.tasks
      params:
        files:
          - src/generated_resmoke_config/${name}.json

  "run jstestfuzz":
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          git clone git@github.com:10gen/jstestfuzz.git

          cp mongodb*/bin/mongod .
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          git clone --depth 1 git@github.com:10gen/mongo-enterprise-modules.git jstests/enterprise_tests
          git clone --depth 1 git@github.com:10gen/QA.git jstests/qa_tests
    - command: shell.exec
      type: test
      params:
        working_dir: src/jstestfuzz
        script: |
          set -o errexit
          set -o verbose

          if [ "Windows_NT" = "$OS" ]; then
            # An "npm" directory might not have been created in %APPDATA% by the Windows installer.
            # Work around the issue by specifying a different %APPDATA% path.
            # See: https://github.com/nodejs/node-v0.x-archive/issues/8141
            export APPDATA=${workdir}/npm-app-data
            export PATH="$PATH:/cygdrive/c/Program Files (x86)/nodejs" # Windows location
          else
            export PATH="$PATH:/opt/node/bin"
          fi

          echo "jstestfuzz self-tests are starting"
          set +o errexit
          npm test > npm_test.log 2>&1
          if [ $? -ne 0 ]; then
            echo "jstestfuzz self-tests failure"
            branch=$(git symbolic-ref --short HEAD)
            commit=$(git show -s --pretty=format:"%h - %an, %ar: %s")
            echo "Git branch: $branch, commit: $commit"
            which node
            node --version
            which npm
            npm --version
            cat npm_test.log
            exit 1
          fi
          rm -f npm_test.log
          set -o errexit
          echo "jstestfuzz self-tests finished"

          npm run ${npm_command|jstestfuzz} -- ${jstestfuzz_vars}

    - command: archive.targz_pack
      params:
        target: "jstests.tgz"
        source_dir: "src/jstestfuzz"
        include:
          - "out/*.js"
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: jstests.tgz
        remote_file: ${project}/${build_variant}/${revision}/jstestfuzz/${task_id}-${execution}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/gzip}
        display_name: Generated Tests - Execution ${execution}

  "run idl tests" :
    - command: shell.exec
      type: test
      params:
        working_dir: src
        script: |
          set -o verbose
          set -o errexit

          ${activate_virtualenv}
          $python -m pip install -r etc/pip/evgtest-requirements.txt
          $python buildscripts/idl/run_tests.py

  "run powercycle test" :
    - command: shell.exec
      type: test
      params:
        working_dir: src
        shell: bash
        script: |
          set -o verbose
          set -o errexit

          ${set_sudo}
          if [ ! -z $sudo ]; then
            remote_sudo="--remoteSudo"
          fi

          ${activate_virtualenv}
          # The virtualenv bin_dir is different for Linux and Windows
          bin_dir=$(find $VIRTUAL_ENV -name activate | sed -e "s,$VIRTUAL_ENV,,;s,activate,,;s,/,,g")
          cmds=". ${virtualenv_dir|venv}/$bin_dir/activate"
          cmds="$cmds; python -u"
          # The remote python operates in a virtualenv
          remote_python="--remotePython=\"$cmds\""

          # Initialize report.json. The report will be finalized by powertest.py.
          report_json="report.json"
          start_time=$(date +%s)
          status="\"fail\""
          failures=0
          exit_code=1
          end_time=$start_time
          elapsed_secs=0
          echo "{\"failures\": $failures, \"results\": [{\"status\": $status, \"exit_code\": $exit_code, \"test_file\": \"${task_name}\", \"start\": $start_time, \"end\": $end_time, \"elapsed\": $elapsed_secs}]}" > $report_json
          generate_report_json="--reportJsonFile=$report_json"

          # Windows task overrides:
          #   - Execute 10 test loops
          #   - Cap the maximum number of clients to 10 each
          if [ "Windows_NT" = "$OS" ]; then
            test_override=--testLoops=10
            max_clients=10
            for client in --numCrudClients --numFsmClients
            do
              override=$(echo ${client_options} | awk "BEGIN {FS=\" |=\"} {for(j=1;j<=NF;j++) if (\$j~/^$client/) {min=(\$(j+1) < $max_clients) ? \$(j+1) : $max_clients; printf \"%s=%d\", \$j,min}}")
              client_override="$client_override $override"
            done
          fi

          # Set an exit trap so we can save the real exit status (see SERVER-34033).
          trap 'echo $? > error_exit.txt; exit 0' EXIT
          config_file=powertest.yml
          eval $python pytests/powertest.py \
            "--saveConfigOptions=$config_file \
            ${connection_options}  \
            ${program_options}     \
            $generate_report_json  \
            $remote_sudo           \
            $remote_python         \
            ${test_options}        \
            $test_override         \
            ${crash_options}       \
            ${client_options}      \
            $client_override       \
            ${mongodb_options}     \
            ${mongod_options}      \
            ${mongod_extra_options}"
          set +o errexit
          $python -u pytests/powertest.py --configFile=$config_file

    - command: expansions.update
      params:
        ignore_missing_file: true
        file: src/${exit_file}

    - command: shell.exec
      params:
        working_dir: src
        shell: bash
        script: |
          # Trigger a system failure if powertest.py failed due to ssh access.
          if [ -n "${ec2_ssh_failure}" ]; then
            echo "ec2_ssh_failure detected - $(cat ${exit_file})"
            exit ${exit_code}
          fi

    - command: shell.exec
      params:
        working_dir: src
        shell: bash
        script: |
          if [ ! -f report.json ]; then
            exit 0
          fi
          grep -q "pass" report.json
          pass=$?
          # On test success, we only archive mongod.log.
          if [ $pass -eq 0 ]; then
            echo "ec2_artifacts: ${log_path}" > ec2_artifacts.yml
          fi

    - command: expansions.update
      params:
        ignore_missing_file: true
        file: src/ec2_artifacts.yml

    - command: shell.exec
      type: test
      params:
        shell: bash
        script: |
          # Test exits from here with specified exit_code.
          if [ -n "${exit_code}" ]; then
            # Python program saved exit_code
            exit_code=${exit_code}
          elif [ -f error_exit.txt ]; then
            # Bash trap exit_code
            exit_code=$(cat error_exit.txt)
          else
            exit_code=0
          fi
          echo "Exiting powercycle with code $exit_code"
          exit $exit_code


  "do multiversion setup" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        ${activate_virtualenv}
        # The Windows build variants are running python 2.7.3 and require TLS 1.2 from pyOpenSSL
        python2 -m pip install 'pyOpenSSL ; sys_platform == "win32" or sys_platform == "cygwin"'

        rm -rf /data/install /data/multiversion
        $python buildscripts/setup_multiversion_mongodb.py   \
          --installDir /data/install                         \
          --linkDir /data/multiversion                       \
          --edition ${multiversion_edition|base}             \
          --platform ${multiversion_platform|linux}          \
          --architecture ${multiversion_architecture|x86_64} \
          --useLatest 3.2 3.4 3.6 4.0 4.0.1

  "do snmp setup" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        mkdir -p snmpconf
        cp -f src/mongo/db/modules/enterprise/docs/mongod.conf.master snmpconf/mongod.conf

  "do watchdog setup" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        bash src/mongo/db/modules/enterprise/jstests/watchdog/charybdefs_setup.sh

  "cleanup environment" :
    command: shell.exec
    params:
      script: |
        set -o verbose

        rm -rf src /data/db/* mongo-diskstats* mongo-*.tgz ~/.aws ~/.boto venv

  "kill processes" :
    command: shell.exec
    params:
      silent: true
      script: |
        process_kill_list="(^cl\.exe$|bsondump|java|lein|lldb|mongo|python|_test$|_test\.exe$)"
        # Exclude Evergreen agent processes and other system daemons
        process_exclude_list="(main|tuned|evergreen)"

        if [ "Windows_NT" = "$OS" ]; then
          # Get the list of Windows tasks (tasklist list format):
          # - Transpose the Image Name and PID
          # - The first column has the process ID
          # - The second column (and beyond) has task name
          # - Grep for the task names of interest while ignoring any names that are in the exclude list

          processes=$(tasklist /fo:csv | awk -F'","' '{x=$1; gsub("\"","",x); print $2, x}' | grep -iE "$process_kill_list" | grep -ivE "$process_exclude_list")

          # Kill the Windows process by process ID with force (/f)
          kill_process () { pid=$(echo $1 | cut -f1 -d ' '); echo "Killing process $1"; taskkill /pid "$pid" /f; }
        else
          # Get the list of Unix tasks (pgrep full & long):
          # - Grep for the task names of interest while ignoring any names that are in the exclude list
          # - The first column has the process ID
          # - The second column (and beyond) has task name

          # There are 2 "styles" of pgrep, figure out which one works.
          # Due to https://bugs.launchpad.net/ubuntu/+source/procps/+bug/1501916
          # we cannot rely on the return status ($?) to detect if the option is supported.
          pgrep -f --list-full ".*" 2>&1 | grep -qE "(illegal|invalid|unrecognized) option"
          if [ $? -ne 0 ]; then
            pgrep_list=$(pgrep -f --list-full "$process_kill_list")
          else
            pgrep_list=$(pgrep -f -l "$process_kill_list")
          fi

          # Since a process name might have a CR or LF in it, we need to delete any lines from
          # pgrep which do not start with space(s) and 1 digit and trim any leading spaces.
          processes=$(echo "$pgrep_list" | grep -ivE "$process_exclude_list" | sed -e '/^ *[0-9]/!d; s/^ *//; s/[[:cntrl:]]//g;')

          # Kill the Unix process ID with signal KILL (9)
          kill_process () { pid=$(echo $1 | cut -f1 -d ' '); echo "Killing process $1"; kill -9 $pid; }
        fi
        # Since a full process name can have spaces, the IFS (internal field separator)
        # should not include a space, just a LF & CR
        IFS=$(printf "\n\r")
        for process in $processes
        do
          kill_process "$process"
        done

  "run kitchen":
    command: shell.exec
    type: test
    params:
      shell: bash
      working_dir: src/buildscripts/package_test
      script: |
        set -o errexit

        export KITCHEN_ARTIFACTS_URL="https://s3.amazonaws.com/mciuploads/${project}/${build_variant}/${revision}/artifacts/${build_id}.tgz"
        export KITCHEN_SECURITY_GROUP="${kitchen_security_group}"
        export KITCHEN_SSH_KEY_ID="${kitchen_ssh_key_id}"
        export KITCHEN_SUBNET="${kitchen_subnet}"
        export KITCHEN_VPC="${kitchen_vpc}"

        ${activate_virtualenv}
        # set expiration tag 2 hours in the future, since no test should take this long
        export KITCHEN_EXPIRE="$($python -c 'import datetime; print((datetime.datetime.utcnow() + datetime.timedelta(hours=2)).strftime("%Y-%m-%d %H:%M:%S"))')"

        for i in {1..3}
        do
          # kitchen commands use regex so 'kitchen verify amazon' matches both amazon and amazon2
          # that's why we pass $ at the end of "${packager_distro}"
          if ! kitchen verify "${packager_distro}"\$; then
            verified="false"
            kitchen destroy "${packager_distro}"\$ || true
            sleep 30
          else
            verified="true"
            break
          fi
        done

        kitchen destroy "${packager_distro}"\$ || true
        test "$verified" = "true"

  "fetch test_lifecycle.yml":
  - command: shell.exec
    type: test
    params:
      working_dir: src
      script: |
        set -o verbose

        ${activate_virtualenv}
        $python buildscripts/fetch_test_lifecycle.py                      \
            --metadataRepo git@github.com:mongodb/mongo-test-metadata.git \
            --lifecycleFile etc/test_lifecycle.yml                        \
            --referencesFile references.yml                               \
            --destinationFile etc/test_lifecycle.yml                      \
            --revision ${revision}                                        \
            ${project}
        exit_code=$?
        if [ ${fail_task_on_error|false} = true ]; then
          exit $exit_code
        else
          exit 0
        fi

  "copy ec2 monitor files": &copy_ec2_monitor_files
    command: shell.exec
    params:
      background: true
      system_log: true
      working_dir: src
      silent: false
      script: |
        while [ 1 ]
        do
          # Tar/zip monitor files on remote host.
          if [ -z "${ec2_monitor_files}" ] || [ -z "${instance_id}" ]; then
            exit 0
          fi
          # Ensure we use the latest private_ip_address, as it could change if the EC2 instance
          # has been stopped and started.
          ${activate_virtualenv}
          # Specify '--mode start' to ensure the remote instance is running.
          monitor_ec2_yml=monitor_ec2.yml
          $python buildscripts/aws_ec2.py --imageId ${instance_id} --mode start --yamlFile $monitor_ec2_yml
          echo "AMI EC2 instance ${instance_id} status: $(cat $monitor_ec2_yml)"
          private_ip_address=$($python buildscripts/yaml_key_value.py --yamlFile $monitor_ec2_yml --yamlKey private_ip_address)
          if [ -z "$private_ip_address" ]; then
            echo "Cannot determine the IP address for the remote monitor."
            continue
          fi
          cmd="${tar|tar} czf ec2_monitor_files.tgz ${ec2_monitor_files}"
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ssh_connection_options="$ssh_connection_options -o ConnectionAttempts=3"
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@$private_ip_address             \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmd"
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@$private_ip_address             \
            --operation "copy_from"                          \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --file ec2_monitor_files.tgz
          sleep 30
        done

  "set up EC2 instance": &set_up_ec2_instance
    - command: shell.exec
      params:
        working_dir: src
        script: |

          set -o errexit
          ${activate_virtualenv}
          python2 -m pip install -r etc/pip/powercycle-requirements.txt

          if [ ! -z "${subnet_id}" ]; then
            subnet_id="-n ${subnet_id}"
          fi

          for security_group_id in ${security_group_ids}
          do
            security_group_ids="$security_group_ids -g $security_group_id"
          done

          if [ -z "${security_group_ids}" ]; then
            for security_group in ${security_groups}
            do
              security_groups="$security_groups -s $security_group"
            done
          fi

          if [ -n "${ec2_expire_hours}" ]; then
            expire_hours="-e ${ec2_expire_hours}"
            # Since Windows hosts are expensive to keep running we'll expire it after 3 hours.
            if [ "Windows_NT" = "$OS" ]; then
              expire_hours="-e 3"
            fi
          fi

          # Clone another instance of this host in EC2.
          buildscripts/launch_evergreen_ec2_instance.sh \
            $expire_hours                               \
            -k ${ssh_key_id}                            \
            $security_groups                            \
            $security_group_ids                         \
            $subnet_id                                  \
            -t "AMI Evergreen ${task_id}"               \
            -y ${aws_ec2_yml}

    - command: expansions.update
      params:
        file: src/${aws_ec2_yml}

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          # Copy mount_drives.sh script to remote host.
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --operation "copy_to"                            \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --file buildscripts/mount_drives.sh

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          # Mount /data on the attached drive(s), more than 1 indicates a RAID set.
          ${set_sudo}
          script_opts="-d '${data_device_names}'"
          if [ ! -z "${raid_data_device_name}" ]; then
            script_opts="$script_opts -r ${raid_data_device_name}"
          fi
          if [ ! -z "${fstype}" ]; then
            script_opts="$script_opts -t ${fstype}"
          fi
          if [ ! -z "${fs_options}" ]; then
            script_opts="$script_opts -o '${fs_options}'"
          fi
          # Mount /log on the attached drive.
          if [ ! -z "${log_device_name}" ]; then
            script_opts="$script_opts -l '${log_device_name}'"
            log="/log"
          fi
          group=$(id -Gn $USER | cut -f1 -d ' ') || true
          user_group="$USER:$group"
          script_opts="$script_opts -u $user_group"
          data_db=/data/db
          cmds="$sudo bash mount_drives.sh $script_opts; mount; ls -ld $data_db $log; df"
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmds"

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          # Create remote_dir, if specified as expansion macro and is not '.' (pwd).
          if [[ -z "${remote_dir|}" || ${remote_dir} == "." ]]; then
            exit 0
          fi
          ${set_sudo}
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          group=$(id -Gn $USER | cut -f1 -d ' ') || true
          user_group="$USER:$group"
          set_permission="chmod 777 ${remote_dir}"
          if [ "Windows_NT" = "$OS" ]; then
            set_permission="setfacl -s user::rwx,group::rwx,other::rwx ${remote_dir}"
          fi
          cmds="$sudo mkdir -p ${remote_dir}; $sudo chown $user_group ${remote_dir}; $set_permission; ls -ld ${remote_dir}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmds"

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          # Copy buildscripts, pytests and mongoDB executables to the remote host.
          file_param="--file etc --file buildscripts --file pytests"
          mongo_executables="mongo mongod mongos"
          for executable in $mongo_executables
          do
            file_param="$file_param --file $executable${exe}"
          done
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --operation "copy_to"                            \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            $file_param                                      \
            --remoteDir ${remote_dir}

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          # Set up virtualenv on remote.
          cmds="python_loc=\$(which \${python|/opt/mongodbtoolchain/v3/bin/python2})"
          cmds="$cmds; remote_dir=${remote_dir|.}"
          cmds="$cmds; if [ \"Windows_NT\" = \"$OS\" ]; then python_loc=\$(cygpath -w \$python_loc); remote_dir=\$(cygpath -w \$remote_dir); fi"
          cmds="$cmds; virtualenv --python \$python_loc --system-site-packages ${virtualenv_dir|venv}"
          cmds="$cmds; activate=\$(find ${virtualenv_dir|venv} -name 'activate')"
          cmds="$cmds; . \$activate"
          cmds="$cmds; pip2 install -r \$remote_dir/etc/pip/powercycle-requirements.txt"
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmds"

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          if [ "Windows_NT" = "$OS" ]; then
            exit 0
          fi
          # Enable core dumps on non-Windows remote hosts.
          # The core pattern must specify a director, since mongod --fork will chdir("/")
          # and cannot generate a core dump there (see SERVER-21635).
          # We need to reboot the host for the core limits to take effect.
          ${set_sudo}
          core_pattern=${remote_dir}/dump_%e.%p.core
          sysctl_conf=/etc/sysctl.conf
          cmds="ulimit -a"
          cmds="$cmds; echo \"$USER - core unlimited\" | $sudo tee -a /etc/security/limits.conf"
          cmds="$cmds; if [ -f $sysctl_conf ]"
          cmds="$cmds; then grep ^kernel.core_pattern $sysctl_conf"
          cmds="$cmds;    if [ \$? -eq  0 ]"
          cmds="$cmds;    then $sudo sed -i \"s,kernel.core_pattern=.*,kernel.core_pattern=$core_pattern,\" $sysctl_conf"
          cmds="$cmds;    else echo \"kernel.core_pattern=$core_pattern\" | $sudo tee -a $sysctl_conf"
          cmds="$cmds;    fi"
          cmds="$cmds; else echo Cannot change the core pattern and no core dumps will be generated."
          cmds="$cmds; fi"
          cmds="$cmds; $sudo reboot"
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmds"

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          if [ "Windows_NT" = "$OS" ]; then
            exit 0
          fi
          # Always exit successfully, as this is just informational.
          trap 'echo "Trapped exit code $?, exiting with 0"; exit 0' EXIT
          # Print the ulimit & kernel.core_pattern
          cmds="uptime"
          cmds="$cmds; ulimit -a"
          cmds="$cmds; if [ -f /sbin/sysctl ]"
          cmds="$cmds; then /sbin/sysctl kernel.core_pattern"
          cmds="$cmds; fi"
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|3}                       \
            --commands "$cmds"

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          ${set_sudo}
          # Set up curator to collect system & process stats on remote.
          if [ "Windows_NT" = "$OS" ]; then
             variant=windows-64
          else
             variant=ubuntu1604
          fi
          # Download stable version of curator
          curator_hash=117d1a65256ff78b6d15ab79a1c7088443b936d0
          curator_url="https://s3.amazonaws.com/boxes.10gen.com/build/curator/curator-dist-$variant-$curator_hash.tar.gz"
          cmds="curl -s $curator_url | tar -xzv"
          if [ "Windows_NT" = "$OS" ]; then
            # Since curator runs as SYSTEM user, ensure the output files can be accessed.
            cmds="$cmds; touch ${monitor_system_file}; chmod 777 ${monitor_system_file}"
            cmds="$cmds; cygrunsrv --install curator_sys --path curator --chdir \$HOME --args 'stat system --file ${monitor_system_file}'"
            cmds="$cmds; touch ${monitor_proc_file}; chmod 777 ${monitor_proc_file}"
            cmds="$cmds; cygrunsrv --install curator_proc --path curator --chdir \$HOME --args 'stat process-all --file ${monitor_proc_file}'"
            cmds="$cmds; cygrunsrv --start curator_sys"
            cmds="$cmds; cygrunsrv --start curator_proc"
          else
            cmds="$cmds; cmd=\"@reboot cd \$HOME && $sudo ./curator stat system >> ${monitor_system_file}\""
            cmds="$cmds; (crontab -l ; echo \"\$cmd\") | crontab -"
            cmds="$cmds; cmd=\"@reboot cd \$HOME && $sudo ./curator stat process-all >> ${monitor_proc_file}\""
            cmds="$cmds; (crontab -l ; echo \"\$cmd\") | crontab -"
            cmds="$cmds; crontab -l"
            cmds="$cmds; { $sudo \$HOME/curator stat system --file ${monitor_system_file} > /dev/null 2>&1 & $sudo \$HOME/curator stat process-all --file ${monitor_proc_file} > /dev/null 2>&1 & } & disown"
          fi
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmds"

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          ${set_sudo}
          # Many systems have the firewall disabled, by default. In case the firewall is
          # enabled we add rules for the mongod ports on the remote.
          # RHEL 7 firewall rules
          if [ ! -z "$(which firewall-cmd 2> /dev/null)" ]; then
            cmds="$sudo firewall-cmd --permanent --zone=public --add-port=ssh/tcp"
            cmds="$cmds; $sudo firewall-cmd --permanent --zone=public --add-port=${standard_port}/tcp"
            cmds="$cmds; $sudo firewall-cmd --permanent --zone=public --add-port=${secret_port}/tcp"
            cmds="$cmds; $sudo firewall-cmd --reload"
            cmds="$cmds; $sudo firewall-cmd --list-all"
          # ArchLinux, Debian, RHEL 6 firewall rules
          elif [ ! -z "$($sudo iptables --list 2> /dev/null)" ]; then
            cmds="$sudo iptables -I INPUT 1 -p tcp --dport ssh -j ACCEPT"
            cmds="$cmds; $sudo iptables -I INPUT 1 -p tcp --dport ${standard_port} -j ACCEPT"
            cmds="$cmds; $sudo iptables -I INPUT 1 -p tcp --dport ${secret_port} -j ACCEPT"
            if [ -d /etc/iptables ]; then
              rules_file=/etc/iptables/iptables.rules
            elif [ -f /etc/sysconfig/iptables ]; then
              rules_file=/etc/sysconfig/iptables
            else
              rules_file=/etc/iptables.up.rules
            fi
            cmds="$cmds; $sudo iptables-save | $sudo tee $rules_file"
            cmds="$cmds; $sudo iptables --list-rules"
          elif [ ! -z "$($sudo service iptables status 2> /dev/null)" ]; then
            cmds="$sudo iptables -I INPUT 1 -p tcp --dport ssh -j ACCEPT"
            cmds="$cmds; $sudo iptables -I INPUT 1 -p tcp --dport ${standard_port} -j ACCEPT"
            cmds="$cmds; $sudo iptables -I INPUT 1 -p tcp --dport ${secret_port} -j ACCEPT"
            cmds="$cmds; $sudo service iptables save"
            cmds="$cmds; $sudo service iptables status"
          # Ubuntu firewall rules
          elif [ ! -z "$($sudo ufw status 2> /dev/null)" ]; then
            cmds="$sudo ufw allow ssh/tcp"
            cmds="$cmds; $sudo ufw allow ${standard_port}/tcp"
            cmds="$cmds; $sudo ufw allow ${secret_port}/tcp"
            cmds="$cmds; $sudo ufw reload"
            cmds="$cmds; $sudo ufw status"
          # SuSE firewall rules
          # TODO: Add firewall rules using SuSEfirewall2
          elif [ ! -z "$($sudo /sbin/SuSEfirewall2 help 2> /dev/null)" ]; then
            cmds="$sudo /sbin/SuSEfirewall2 stop"
            cmds="$cmds; $sudo /sbin/SuSEfirewall2 off"
          # Windows firewall rules
          elif [ ! -z "$(netsh advfirewall show store 2> /dev/null)" ]; then
            add_rule="netsh advfirewall firewall add rule"
            cmds="$add_rule name='MongoDB port ${standard_port} in' dir=in action=allow protocol=TCP localport=${standard_port}"
            cmds="$cmds; $add_rule name='MongoDB port ${standard_port} out' dir=in action=allow protocol=TCP localport=${standard_port}"
            cmds="$cmds; $add_rule name='MongoDB port ${secret_port} in' dir=in action=allow protocol=TCP localport=${secret_port}"
            cmds="$cmds; $add_rule name='MongoDB port ${secret_port} out' dir=in action=allow protocol=TCP localport=${secret_port}"
            cmds="$cmds; netsh advfirewall firewall show rule name=all | grep -A 13 'MongoDB'"
          else
            echo "Firewall not active or unknown firewall command on this platform"
            exit 0
          fi
          set -o errexit
          if [ ! -z "$cmds" ]; then
            ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
            ${activate_virtualenv}
            $python buildscripts/remote_operations.py          \
              --verbose                                        \
              --userHost $USER@${private_ip_address}           \
              --sshConnectionOptions "$ssh_connection_options" \
              --retries ${ssh_retries|0}                       \
              --commands "$cmds"
          fi

    - command: shell.exec
      params:
        shell: bash
        working_dir: src
        script: |
          set -o errexit
          if [[ "Windows_NT" != "$OS" || -z "${windows_crash_zip}" ]]; then
            exit 0
          fi
          # Install NotMyFault, used to crash Windows.
          cmds="curl -s -o ${windows_crash_zip} ${windows_crash_dl}"
          cmds="$cmds; unzip -q ${windows_crash_zip} -d ${windows_crash_dir}"
          cmds="$cmds; chmod +x ${windows_crash_dir}/*.exe"
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          ${activate_virtualenv}
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries|0}                       \
            --commands "$cmds"

    - *copy_ec2_monitor_files

  ### Determine & set remote EC2 IP address ###
  "get EC2 address": &get_ec2_address
    command: shell.exec
    params:
      shell: bash
      working_dir: src
      script: |
        if [ -z "${instance_id}" ]; then
          exit 0
        fi
        # Ensure we use the latest private_ip_address, as it could change if the EC2 instance
        # has been stopped and started.
        ${activate_virtualenv}
        # Specify '--mode start' to ensure the remote instance is running.
        now=$(date +'%Y%m%d%H%M%S')
        aws_ec2_status_yml=aws_ec2_status.yml
        $python buildscripts/aws_ec2.py            \
          --imageId ${instance_id}                 \
          --mode start                             \
          --yamlFile $aws_ec2_status_yml           \
          --consoleOutputFile ec2_console_$now.log \
          --consoleScreenshotFile ec2_console_screen_shot_$now.jpg
        private_ip_address=$($python buildscripts/yaml_key_value.py --yamlFile $aws_ec2_status_yml --yamlKey private_ip_address)
        echo "private_ip_address: $private_ip_address" > private_ip_address.yml

  "update EC2 address": &update_ec2_address
    command: expansions.update
    params:
      file: src/private_ip_address.yml

  ### Process & archive remote EC2 artifacts ###
  "tar EC2 artifacts": &tar_ec2_artifacts
    command: shell.exec
    params:
      shell: bash
      working_dir: src
      script: |
        # Tar/zip artifacts on remote host.
        if [[ -z "${ec2_artifacts}" || -n "${ec2_ssh_failure}" ]]; then
          exit 0
        fi
        cmd="${tar|tar} czf ec2_artifacts.tgz ${ec2_artifacts}"
        ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
        ${activate_virtualenv}
        $python buildscripts/remote_operations.py          \
          --verbose                                        \
          --userHost $USER@${private_ip_address}           \
          --sshConnectionOptions "$ssh_connection_options" \
          --retries ${ssh_retries|0}                       \
          --commands "$cmd"

  "copy EC2 artifacts": &copy_ec2_artifacts
    command: shell.exec
    params:
      shell: bash
      working_dir: src
      script: |
        # Copy remote artifacts.
        if [[ -z "${ec2_artifacts}" || -n "${ec2_ssh_failure}" ]]; then
          exit 0
        fi
        ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
        ${activate_virtualenv}
        $python buildscripts/remote_operations.py          \
          --verbose                                        \
          --userHost $USER@${private_ip_address}           \
          --operation "copy_from"                          \
          --sshConnectionOptions "$ssh_connection_options" \
          --retries ${ssh_retries|0}                       \
          --file ec2_artifacts.tgz

  "cleanup EC2 instance": &cleanup_ec2_instance
    command: shell.exec
    params:
      shell: bash
      working_dir: src
      script: |
        # We do not terminate the EC2 instance if there was an ec2_ssh_failure.
        if [[ -z ${instance_id|""} || -n "${ec2_ssh_failure}" ]]; then
          exit 0
        fi
        ${activate_virtualenv}
        echo "Terminating $instance_id"
        aws_ec2=$($python buildscripts/aws_ec2.py --imageId ${instance_id} --mode terminate)
        echo "Terminated AMI EC2 instance: $aws_ec2"

  "gather remote mongo coredumps": &gather_remote_mongo_coredumps
    command: shell.exec
    params:
      shell: bash
      working_dir: "src"
      script: |
        if [[ ! -f ${aws_ec2_yml|""} || -n "${ec2_ssh_failure}" ]]; then
          exit 0
        fi
        ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
        remote_dir=${remote_dir|.}
        # Find all core files and move to $remote_dir
        cmds="core_files=\$(/usr/bin/find -H . \( -name '*.core' -o -name '*.mdmp' \) 2> /dev/null)"
        cmds="$cmds; if [ -z \"\$core_files\" ]; then exit 0; fi"
        cmds="$cmds; echo Found remote core files \$core_files, moving to \$(pwd)"
        cmds="$cmds; for core_file in \$core_files"
        cmds="$cmds; do base_name=\$(echo \$core_file | sed 's/.*\///')"
        cmds="$cmds;   if [ ! -f \$base_name ]; then mv \$core_file .; fi"
        cmds="$cmds; done"
        ${activate_virtualenv}
        $python buildscripts/remote_operations.py          \
          --verbose                                        \
          --userHost $USER@${private_ip_address}           \
          --sshConnectionOptions "$ssh_connection_options" \
          --retries ${ssh_retries}                         \
          --commands "$cmds"                               \
          --commandDir $remote_dir

  "copy remote mongo coredumps": &copy_remote_mongo_coredumps
    command: shell.exec
    params:
      shell: bash
      working_dir: "src"
      script: |
        if [[ ! -f ${aws_ec2_yml|""} || -n "${ec2_ssh_failure}" ]]; then
          exit 0
        fi
        ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
        remote_dir=${remote_dir|.}
        ${activate_virtualenv}
        $python buildscripts/remote_operations.py          \
          --verbose                                        \
          --userHost $USER@${private_ip_address}           \
          --operation "copy_from"                          \
          --sshConnectionOptions "$ssh_connection_options" \
          --retries ${ssh_retries}                         \
          --file "$remote_dir/*.core"                      \
          --file "$remote_dir/*.mdmp"
        # Since both type of core files do not exist on the same host, this command
        # will always return non-zero. As the core file retrieval is optional, we
        # always exit successfully.
        exit 0

  "archive remote EC2 artifacts": &archive_remote_ec2_artifacts
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/ec2_artifacts.tgz
      remote_file: ${project}/${build_variant}/${revision}/remote_ec2/remote_ec2_artifacts-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Remote EC2 Artifacts - Execution ${execution}
      optional: true

  "archive remote EC2 monitor files": &archive_remote_ec2_monitor_files
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/ec2_monitor_files.tgz
      remote_file: ${project}/${build_variant}/${revision}/remote_ec2/remote_ec2_monitor-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Remote EC2 Monitor - Execution ${execution}
      optional: true

  "gather EC2 console artifacts": &gather_ec2_console_artifacts
    command: shell.exec
    params:
      working_dir: src
      script: |
        ec2_console_files=$(ls ec2_console* 2> /dev/null)
        if [ -n "$ec2_console_files" ]; then
          ${tar|tar} czf ec2_console_files.tgz $ec2_console_files
        fi

  "archive EC2 console artifacts": &archive_ec2_console_artifacts
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/ec2_console_files.tgz
      remote_file: ${project}/${build_variant}/${revision}/ec2/ec2_console-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/x-gzip}
      display_name: EC2 Console files - Execution ${execution}
      optional: true

  "save ec2 task artifacts":
    - *get_ec2_address
    - *update_ec2_address
    - *tar_ec2_artifacts
    - *copy_ec2_artifacts
    - *gather_remote_mongo_coredumps
    - *copy_remote_mongo_coredumps
    - *gather_ec2_console_artifacts
    - *archive_ec2_console_artifacts
    - *cleanup_ec2_instance
    - *archive_remote_ec2_artifacts
    - *archive_remote_ec2_monitor_files

  ### Process & archive local client logs ###
  "tar local client logs": &tar_local_client_logs
    command: shell.exec
    params:
      working_dir: src
      script: |
        client_logs=$(ls crud*.log fsm*.log 2> /dev/null)
        if [ ! -z "$client_logs" ]; then
          ${tar|tar} czf client-logs.tgz $client_logs
        fi

  "archive local client logs": &archive_local_client_logs
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/client-logs.tgz
      remote_file: ${project}/${build_variant}/${revision}/client_logs/mongo-client-logs-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Client logs - Execution ${execution}
      optional: true

  "save local client logs":
    - *tar_local_client_logs
    - *archive_local_client_logs

  ### Set expansion macros used in each task ###
  "set task expansion macros":
    command: expansions.update
    params:
      updates:
      - key: activate_virtualenv
        value: |
          # check if virtualenv is set up
          if [ -d "${workdir}/venv" ]; then
            if [ "Windows_NT" = "$OS" ]; then
              # Need to quote the path on Windows to preserve the separator.
              . "${workdir}/venv/Scripts/activate" 2> /tmp/activate_error.log
            else
              . ${workdir}/venv/bin/activate 2> /tmp/activate_error.log
            fi
            if [ $? -ne 0 ]; then
              echo "Failed to activate virtualenv: $(cat /tmp/activate_error.log)"
            fi
            python=python
          else
            python=${python|/opt/mongodbtoolchain/v3/bin/python2}
          fi
          echo "python set to $(which $python)"
      - key: activate_virtualenv_3
        value: |
          # check if virtualenv for python3 is set up
          if [ -d "${workdir}/venv_3" ]; then
            if [ "Windows_NT" = "$OS" ]; then
              # Need to quote the path on Windows to preserve the separator.
              . "${workdir}/venv_3/Scripts/activate" 2> /tmp/activate_error.log
            else
              . ${workdir}/venv_3/bin/activate 2> /tmp/activate_error.log
            fi
            if [ $? -ne 0 ]; then
              echo "Failed to activate virtualenv: $(cat /tmp/activate_error.log)"
            fi
            python=python
          else
            if [ "Windows_NT" = "$OS" ]; then
              python=/cygdrive/c/python/python36/python
            else
              python=${python3|/opt/mongodbtoolchain/v3/bin/python3}
            fi
          fi
          echo "python set to $(which $python)"
      - key: posix_workdir
        value: eval 'if [ "Windows_NT" = "$OS" ]; then echo $(cygpath -u "${workdir}"); else echo ${workdir}; fi'
      # For ssh disable the options GSSAPIAuthentication, CheckHostIP, StrictHostKeyChecking
      # & UserKnownHostsFile, since these are local connections from one AWS instance to another.
      - key: ssh_connection_options
        value: -o GSSAPIAuthentication=no -o CheckHostIP=no -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=30 -o ConnectionAttempts=20
      - key: ssh_retries
        value: "10"
      - key: set_sudo
        value: |
          set -o > /tmp/settings.log
          set +o errexit
          grep errexit /tmp/settings.log | grep on
          errexit_on=$?
          # Set errexit "off".
          set +o errexit
          sudo=
          # Use sudo, if it is supported.
          sudo date > /dev/null 2>&1
          if [ $? -eq 0 ]; then
            sudo=sudo
          fi
          # Set errexit "on", if previously enabled.
          if [ $errexit_on -eq 0 ]; then
            set -o errexit
          fi
      - key: mongo_binaries
        value: ${project}/${build_variant}/${revision}/binaries/mongo-${build_id}.${ext|tgz}
      - key: mongo_debugsymbols
        value: ${project}/${build_variant}/${revision}/debugsymbols/debugsymbols-${build_id}.${ext|tgz}
      - key: mongo_shell
        value: ${project}/${build_variant}/${revision}/binaries/mongo-shell-${build_id}.${ext|tgz}
      - key: skip_tests
        value: skip_test-${build_id}

  ### Clear and print OOM messages ###
  "clear OOM messages":
      command: shell.exec
      params:
        system_log: true
        script: |

          ulimit -a
          # Clear the dmesg ring buffer. The "post" phase will check dmesg for OOM messages.
          ${set_sudo}
          $sudo dmesg -c > /dev/null 2>&1
          if [ $? -eq 0 ]; then
            echo "Cleared the dmesg ring buffer"
          else
            echo "Could not clear the dmesg ring buffer"
          fi

  "print OOM messages":
    # Print out any Out of Memory killed process messages.
    command: shell.exec
    params:
      system_log: true
      working_dir: src # Temporary files created in src will be cleaned up in "pre".
      script: |
        ${set_sudo}
        # Use dmesg -T option, if supported, to display timestamps.
        dmesg=dmesg
        $sudo dmesg -T > /dev/null 2>&1
        if [ $? -eq 0 ]; then
          dmesg="dmesg -T"
        fi
        $sudo $dmesg 2> /dev/null > dmesg.txt
        if [ $? -ne 0 ]; then
          echo "Cannot check for OOM (Out of memory) killed processes on this platform"
          exit 0
        fi
        grep -iE '(Out of memory|OOM[- ]killer|Killed process)' dmesg.txt > oom.txt
        if [ -s oom.txt ]; then
          echo "OOM (Out of memory) killed processes detected"
          cat oom.txt
        else
          echo "No OOM (Out of memory) killed processes detected"
        fi

  ### Cleanup after the watchdog FUSE testing ###
  "cleanup FUSE watchdog":
    command: shell.exec
    params:
      working_dir: src
      script: |
        if [ -d /data/thrift ]; then
          rm -rf /data/thrift
        fi

        if [ -d /data/charybdefs ]; then
          rm -rf /data/charybdefs
        fi

  ### Process & archive Code Coverage artifacts ###
  "process code coverage data": &process_code_coverage_data
    command: shell.exec
    params:
      working_dir: src
      script: |
        set +o errexit
        if [ -d "./build" ]; then
          file_list=$(find ./build -type f -name "*.gcda")
          if [ -n "$file_list" ]; then
            for gcda_file in $file_list; do
              echo "Processing file $gcda_file"
              /opt/mongodbtoolchain/v3/bin/gcov -i $gcda_file
              base_name=$(echo $gcda_file | rev | cut -f1 -d '/' | cut -f2 -d '.' | rev)
              gcov_file=$base_name.gcda.gcov
              if [ -f "$gcov_file" ]; then
                # Add a prefix to the intermediate file, since it does not have a unique name.
                # Convert the '/' to '#' in the file path.
                file_prefix=$(echo $gcda_file | sed -e 's,^\./,,' | rev | cut -f2- -d '/' | rev | tr -s '/' '#')
                new_gcov_file=$file_prefix#$base_name.gcda.gcov
                if [ ! -f $new_gcov_file ]; then
                  echo "Renaming gcov intermediate file $gcov_file to $new_gcov_file"
                  mv $gcov_file $new_gcov_file
                else
                  # We treat this as a fatal condition and remove all of the coverage files.
                  echo "Not renaming $gcov_file as $new_gcov_file already exists!"
                  rm -f *.gcda.gcov
                  exit 1
                fi
              fi
              rm $gcda_file
            done
          fi
        fi

  "tar code coverage data": &tar_code_coverage_data
    command: archive.targz_pack
    params:
      target: "src/gcov-intermediate-files.tgz"
      source_dir: "src"
      include:
        - "*.gcda.gcov"

  "archive code coverage data": &archive_code_coverage_data
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: "src/gcov-intermediate-files.tgz"
      remote_file: ${project}/${build_variant}/${revision}/gcov/gcov-intermediate-files-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: gcov intermediate files - Execution ${execution}
      optional: true

  "save code coverage data":
    - *process_code_coverage_data
    - *tar_code_coverage_data
    - *archive_code_coverage_data

  "tar jepsen logs": &tar_jepsen_logs
    command: archive.targz_pack
    params:
      target: "src/jepsen-mongod-logs.tgz"
      source_dir: "${workdir}/src/jepsen-workdir"
      include:
        - "./**.log"

  "archive jepsen logs": &archive_jepsen_logs
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/jepsen-mongod-logs.tgz
      remote_file: ${project}/${build_variant}/${revision}/jepsen/jepsen-mongod-logs-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Jepsen mongod Logs - ${execution}
      optional: true

  "tar jepsen results": &tar_jepsen_results
    command: archive.targz_pack
    params:
      target: "src/jepsen-results.tgz"
      source_dir: "src/jepsen-mongodb/store"
      include:
        - "./**"

  "archive jepsen results": &archive_jepsen_results
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/jepsen-results.tgz
      remote_file: ${project}/${build_variant}/${revision}/jepsen/jepsen-results-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Jepsen Test Results - ${execution}
      optional: true

  "save jepsen artifacts":
    - *tar_jepsen_logs
    - *archive_jepsen_logs
    - *tar_jepsen_results
    - *archive_jepsen_results

  ### Process & archive mongo coredumps ###
  "gather mongo coredumps": &gather_mongo_coredumps
    command: shell.exec
    params:
      working_dir: "src"
      script: |
        # Find all core files and move to src
        core_files=$(/usr/bin/find -H .. \( -name "*.core" -o -name "*.mdmp" \) 2> /dev/null)
        for core_file in $core_files
        do
          base_name=$(echo $core_file | sed "s/.*\///")
          # Move file if it does not already exist
          if [ ! -f $base_name ]; then
            mv $core_file .
          fi
        done

  "tar mongo coredumps": &tar_mongo_coredumps
    command: archive.targz_pack
    params:
      target: "mongo-coredumps.tgz"
      source_dir: "src"
      include:
        - "./**.core"
        - "./**.mdmp" # Windows: minidumps

  "archive mongo coredumps": &archive_mongo_coredumps
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: mongo-coredumps.tgz
      remote_file: ${project}/${build_variant}/${revision}/coredumps/mongo-coredumps-${build_id}-${task_name}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Core Dumps - Execution ${execution}
      optional: true

  "save mongo coredumps":
  - *gather_mongo_coredumps
  - *tar_mongo_coredumps
  - *archive_mongo_coredumps

  ### Process & archive failed unittest artifacts ###
  "gather failed unittests": &gather_failed_unittests
    command: shell.exec
    params:
      working_dir: "src"
      script: |
        mkdir unittest_binaries || true
        # Find all core files
        core_files=$(/usr/bin/find -H . \( -name "dump_*.core" -o -name "*.mdmp" \) 2> /dev/null)
        for core_file in $core_files
        do
          # A core file name does not always have the executable name that generated it.
          # See http://stackoverflow.com/questions/34801353/core-dump-filename-gets-thread-name-instead-of-executable-name-with-core-pattern
          # On platforms with GDB, we get the binary name from core file
          gdb=/opt/mongodbtoolchain/gdb/bin/gdb
          if [ -f $gdb ]; then
            binary_file=$($gdb -batch --quiet -ex "core $core_file" 2> /dev/null | grep "Core was generated" | cut -f2 -d "\`" | cut -f1 -d "'" | cut -f1 -d " ")
            binary_file_locations=$binary_file
          else
            # Find the base file name from the core file name, note it may be truncated.
            # Remove leading 'dump_' and trailing '.<pid>.core' or '.<pid or time>.mdmp'
            binary_file=$(echo $core_file | sed "s/.*\///;s/dump_//;s/\..*\.core//;s/\..*\.mdmp//")
            # Locate the binary file. Since the base file name might be truncated, the find
            # may return more than 1 file.
            binary_file_locations=$(/usr/bin/find -H . -name "$binary_file*${exe}" 2> /dev/null)
          fi
          if [ -z "$binary_file_locations" ]; then
            echo "Cannot locate the unittest binary file ($binary_file) that generated the core file $core_file"
          fi
          for binary_file_location in $binary_file_locations
          do
            new_binary_file=unittest_binaries/$(echo $binary_file_location | sed "s/.*\///")
            if [ ! -f $new_binary_file ]; then
              mv $binary_file_location $new_binary_file
            fi
            # On Windows if a .pdb symbol file exists, include it in the archive.
            pdb_file=$(echo $binary_file_location | sed "s/\.exe/.pdb/")
            if [ -f $pdb_file ]; then
              new_pdb_file=unittest_binaries/$(echo $pdb_file | sed "s/.*\///")
              mv $pdb_file $new_pdb_file
            fi
          done
        done

  "tar failed unittests": &tar_failed_unittests
    command: archive.targz_pack
    params:
      target: "mongo-unittests.tgz"
      source_dir: "src/unittest_binaries"
      include:
        - "./*_test${exe}"

  "archive failed unittests": &archive_failed_unittests
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: mongo-unittests.tgz
      remote_file: ${project}/${build_variant}/${revision}/unittests/mongo-unittests-${build_id}-${task_name}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Unit tests - Execution ${execution}
      optional: true

  "save failed unittests":
  - *gather_failed_unittests
  - *tar_failed_unittests
  - *archive_failed_unittests

  "detect failed dbtest": &detect_failed_dbtest
    command: shell.exec
    params:
      working_dir: "src"
      script: |
        if [ -f resmoke_error_code ] && [ -f ../dbtest_unstripped.tgz ]; then
          echo "Task dbtest failed with error $(cat resmoke_error_code), archiving the unstripped binary"
          mv ../dbtest_unstripped.tgz ../dbtest.tgz
        fi

  "archive unstripped dbtest": &archive_unstripped_dbtest
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: dbtest.tgz
      remote_file: ${project}/${build_variant}/${revision}/dbtest/dbtest-${build_id}-${task_name}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: application/tar
      display_name: Unstripped dbtest binary - Execution ${execution}
      optional: true

  "save unstripped dbtest":
  - *detect_failed_dbtest
  - *archive_unstripped_dbtest

  ### Process & archive artifacts from hung processes ###
  "run hang analyzer":
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o verbose

        hang_analyzer_option="-o file -o stdout -p ${hang_analyzer_processes|dbtest,java,mongo,mongod,mongos,python,_test} -g bsondump,mongodump,mongoexport,mongofiles,mongoimport,mongoreplay,mongorestore,mongostat,mongotop"

        if [ ${hang_analyzer_dump_core|true} = true ]; then
          hang_analyzer_option="-c $hang_analyzer_option"
        fi

        ${activate_virtualenv}
        echo "Calling the hang analyzer: PATH=\"/opt/mongodbtoolchain/gdb/bin:$PATH\" $python buildscripts/hang_analyzer.py $hang_analyzer_option"
        PATH="/opt/mongodbtoolchain/gdb/bin:$PATH" $python buildscripts/hang_analyzer.py $hang_analyzer_option

        # Call hang_analyzer.py script for tasks that are running remote mongo processes
        if [ -n "${private_ip_address}" ]; then
          core_ext=core
          if [ "Windows_NT" = "$OS" ]; then
            core_ext=mdmp
          fi
          ssh_connection_options="${ssh_identity} ${ssh_connection_options}"
          # buildscripts must be installed in ${remote_dir} on the remote host.
          remote_dir=${remote_dir|.}

          # Copy mongoDB debug symbols to the remote host.
          debug_files=$(ls *.debug *.dSYM *.pdb 2> /dev/null)
          for debug_file in $debug_files
          do
            file_param="$file_param --file $debug_file"
          done
          if [ ! -z "$file_param" ]; then
            $python buildscripts/remote_operations.py          \
              --verbose                                        \
              --userHost $USER@${private_ip_address}           \
              --operation "copy_to"                            \
              --sshConnectionOptions "$ssh_connection_options" \
              --retries ${ssh_retries}                         \
              $file_param                                      \
              --remoteDir $remote_dir
          fi

          # Activate virtualenv on remote host. The virtualenv bin_dir is different for Linux and
          # Windows.
          bin_dir=$(find $VIRTUAL_ENV -name activate | sed -e "s,$VIRTUAL_ENV,,;s,activate,,;s,/,,g")
          cmds=". ${virtualenv_dir|venv}/$bin_dir/activate"
          # In the 'cmds' variable we pass to remote host, use 'python' instead of '$python' since
          # we don't want to evaluate the local python variable, but instead pass the python string
          # so the remote host will use the right python when the virtualenv is sourced.
          cmds="$cmds; cd ${remote_dir}"
          cmds="$cmds; PATH=\"/opt/mongodbtoolchain/gdb/bin:\$PATH\" python buildscripts/hang_analyzer.py $hang_analyzer_option"
          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries}                         \
            --commands "$cmds"

          $python buildscripts/remote_operations.py          \
            --verbose                                        \
            --userHost $USER@${private_ip_address}           \
            --operation "copy_from"                          \
            --sshConnectionOptions "$ssh_connection_options" \
            --retries ${ssh_retries}                         \
            --file "$remote_dir/debugger*.*"                 \
            --file "$remote_dir/*.$core_ext"
        fi

  "tar hang analyzer debugger files": &tar_hang_analyzer_debugger_files
    command: archive.targz_pack
    params:
      target: "src/mongo-hanganalyzer.tgz"
      source_dir: "src"
      include:
        - "./debugger*.*"

  "archive hang analyzer debugger files": &archive_hang_analyzer_debugger_files
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/mongo-hanganalyzer.tgz
      remote_file: ${project}/${build_variant}/${revision}/hanganalyzer/mongo-hanganalyzer-${build_id}-${task_name}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Hang Analyzer Output - Execution ${execution}
      optional: true

  "save hang analyzer debugger files":
  - *tar_hang_analyzer_debugger_files
  - *archive_hang_analyzer_debugger_files

  ### Process & archive disk statistic artifacts ###
  "tar disk statistics": &tar_disk_statistics
    command: archive.targz_pack
    params:
      target: "diskstats.tgz"
      source_dir: "./"
      include:
        - "./mongo-diskstats*"
        - "./mongo-diskstats*.csv"

  "archive disk statistics": &archive_disk_statistics
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: diskstats.tgz
      remote_file: ${project}/${build_variant}/${revision}/diskstats/mongo-diskstats-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: Disk Stats - Execution ${execution}
      optional: true

  "save disk statistics":
  - *tar_disk_statistics
  - *archive_disk_statistics

  ### Process & archive system resource artifacts ###
  "tar system resource information": &tar_system_resource_information
    command: archive.targz_pack
    params:
      target: "system-resource-info.tgz"
      source_dir: src
      include:
        - "./system_resource_info*"

  "archive system resource information": &archive_system_resource_information
    command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: system-resource-info.tgz
      remote_file: ${project}/${build_variant}/${revision}/systemresourceinfo/mongo-system-resource-info-${task_id}-${execution}.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: System Resource Info - Execution ${execution}
      optional: true

  "save system resource information":
  - *tar_system_resource_information
  - *archive_system_resource_information

  ### Attach report & artifacts ###
  "attach scons config log":
    command: s3.put
    params:
      optional: true
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/build/scons/config.log
      remote_file: ${project}/${build_variant}/${revision}/artifacts/config-${build_id}.log
      bucket: mciuploads
      permissions: public-read
      content_type: text/plain
      display_name: config.log

  "attach report":
    command: attach.results
    params:
      file_location: ${report_file|src/report.json}

  "attach artifacts":
    command: attach.artifacts
    params:
      optional: true
      ignore_artifacts_for_spawn: false
      files:
        - ${archive_file|src/archive.json}


# Pre task steps
pre:
  - func: "kill processes"
  - func: "cleanup environment"
  # The python virtual environment is installed in ${workdir}, which is created in
  # "set up virtualenv".
  - func: "set up virtualenv"
  - func: "set task expansion macros"
  - func: "clear OOM messages"

# Post task steps
post:
  - func: "attach report"
  - func: "attach artifacts"
  - func: "save ec2 task artifacts"
  - func: "call BF Suggestion service"
  - func: "kill processes"
  - func: "save local client logs"
  - func: "save code coverage data"
  - func: "save jepsen artifacts"
  - func: "save mongo coredumps"
  - func: "save failed unittests"
  - func: "save hang analyzer debugger files"
  - func: "save disk statistics"
  - func: "save system resource information"
  - func: "print OOM messages"
  - func: "cleanup FUSE watchdog"
  - func: "cleanup environment"

# Timeout steps
timeout:
  - func: "fetch debugsymbols archive"
  - func: "extract debugsymbols"
  - func: "get EC2 address"
  - func: "update EC2 address"
  - func: "run hang analyzer"


#######################################
#               Tasks                 #
#######################################

## The test_lifecycle_excluded_tasks are a list of tasks names which include:
##   - Non jstests, i.e., compile, unittests
##   - Non standard jstests, i.e., jstestfuzz
## Note that the task name supports glob patterns.
test_lifecycle_excluded_tasks:
- burn_in_tests
- compile*
- benchmarks*
- dbtest*
- "*fuzzer*"
- idl_tests
- integration*
- jepsen*
- jstestfuzz*
- lint
- mongos*
- package
- push
- unittests*

tasks:

## compile - build all scons targets except unittests ##
- name: compile
  depends_on: []
  commands:
    - func: "build new tools"
    - func: "scons compile"
      vars:
        targets: core tools dbtest integration_tests dist dist-debugsymbols distsrc-${ext|tgz} ${msi_target|}
        task_compile_flags: >-
          --use-new-tools
          --build-mongoreplay="${build_mongoreplay}"
          --detect-odr-violations
    - command: shell.exec
      type: test
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ] && [ "${bypass_compile|false}" = "true" ]; then
            exit 0
          fi

          mv mongodb-src-*.${ext|tgz} distsrc.${ext|tgz}
          mv mongodb-*-debugsymbols.${ext|tgz} mongo-debugsymbols.tgz || true
          mv mongodb-*.${ext|tgz} mongodb-binaries.tgz

    # Tar unstripped dbtest, to be archived in case of failure
    - command: archive.targz_pack
      params:
        target: "dbtest_unstripped.tgz"
        source_dir: "src"
        include:
          - "./dbtest*"

    - command: shell.exec
      type: test
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ] && [ "${bypass_compile|false}" = "true" ]; then
            exit 0
          fi

          # If strip is on the path (everywhere except windows) then we should strip the test binaries
          # before tarring them up
          if [ -x ${strip_path|/usr/bin/strip} ]; then
            cat build/integration_tests.txt | xargs ${strip_command|/usr/bin/strip}
            ${strip_command|/usr/bin/strip} dbtest
            ${strip_command|/usr/bin/strip} mongobridge
            ${strip_command|/usr/bin/strip} wt
          fi


    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ] && [ "${bypass_compile|false}" = "true" ]; then
            exit 0
          fi
          ${activate_virtualenv}
          if [ "${has_packages|}" = "true" ] ; then
            cd buildscripts
            $python ${packager_script} --prefix `pwd`/.. --distros ${packager_distro} --tarball `pwd`/../mongodb-binaries.tgz -s ${version} -m HEAD -a ${packager_arch}
            cd ..
          fi

          # Create separate shell archive
          mkdir -p shell-archive/build
          cd shell-archive
          ${platform_decompress|tar xzvf} ../mongodb-binaries.tgz
          find . -mindepth 3 ! -name "mongo${exe}" -type f -exec rm {} \; # delete bin/* except bin/mongo
          $python ../buildscripts/make_archive.py -o mongodb-shell.${ext|tgz} $(find mongodb-* -type f)
          cd ..

  # Test lifecycle is temporarily disabled to reduce load on Evergreen API.
  # - func: "fetch test_lifecycle.yml"
  #   vars:
  #     # Do not fail the task if we fail to fetch the test_lifecycle.yml file
  #     fail_task_on_error: false

    - command: archive.targz_pack
      params:
        target: "artifacts.tgz"
        source_dir: "src"
        include:
          - "src/mongo/db/modules/enterprise/jstests/**"
          - "compile_expansions.yml"
          - "src/mongo/db/modules/subscription/jstests/**"
          - "src/mongo/db/modules/enterprise/docs/**"
          - "*.exe"
          - "jstests/**"
          - "pytests/**"
          - "./test*"
          - "./dbtest*"
          - "./mongobridge*"
          - "./mongoebench*"
          - "./mongoed*"
          - "./wt*"
          - "buildscripts/**"
          - "*Example"
          - "*Test"
          - "./**.pdb"
          - "./**.msi"
          - "./etc/pip/**"
          - "./etc/scons/**"
          - "./etc/*san.suppressions"
          - "./etc/repo_config.yaml"
          - "./etc/test_lifecycle.yml"
          - "./etc/test_retrial.yml"
          - "./build/integration_tests/**"
          - "./build/integration_tests.txt"
          - "./build/**.gcno"
          - "repo/**"
          - "src/mongo/util/options_parser/test_config_files/**"
          - "library_dependency_graph.json"
          - "src/third_party/JSON-Schema-Test-Suite/tests/draft4/**"
          - "bypass_compile_expansions.yml"
          - "patch_files.txt"
          - "artifacts.json"
        exclude_files:
          - "*_test.pdb"
    - func: "upload debugsymbols"
    - command: s3.put
      params:
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb-binaries.tgz
        remote_file: ${mongo_binaries}
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/gzip}
        display_name: Binaries
    - command: s3.put
      params:
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/shell-archive/mongodb-shell.${ext|tgz}
        remote_file: ${mongo_shell}
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/gzip}
        display_name: Shell
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: artifacts.tgz
        remote_file: ${project}/${build_variant}/${revision}/artifacts/${build_id}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: Artifacts
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/distsrc.${ext|tgz}
        remote_file: ${project}/${build_variant}/${revision}/sources/mongo-src-${build_id}.${ext|tgz}
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/gzip}
        display_name: Source tarball
        # We only need to upload the source tarball from one of the build variants
        # because it should be the same everywhere, so just use rhel70/windows-64-2k8-ssl.
        build_variants: [ rhel70, windows-64-2k8-ssl ]
    - command: s3.put
      params:
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/scons_cache.log
        content_type: text/plain
        remote_file: ${project}/${build_variant}/${revision}/scons-cache-${build_id}-${execution}.log
        bucket: mciuploads
        permissions: public-read
        display_name: SCons cache debug log
    # For patch builds that bypass compile, we upload links to pre-existing tarballs, except for the
    # artifacts.tgz.
    - command: attach.artifacts
      params:
        optional: true
        ignore_artifacts_for_spawn: false
        files:
          - src/artifacts.json

## compile_all - build all scons targets ##
- name: compile_all
  commands:
    - func: "build new tools"
    - func: "scons compile"
      vars:
        targets: all
        task_compile_flags: >-
          --use-new-tools
          --build-mongoreplay="${build_mongoreplay}"
          --detect-odr-violations
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/library_dependency_graph.json
        remote_file: ${project}/${build_variant}/${revision}/library_dependency_graph.${build_id}.json
        bucket: mciuploads
        permissions: public-read
        content_type: application/json
        display_name: Library Dependency Graph (library_dependency_graph.json)
        build_variants: [enterprise-rhel-70-64-bit-kitchen-sink] # This must be the Dagger variant

## compile_unittests - build unittests ##
- name: compile_unittests
  commands:
    - func: "scons compile"
      vars:
        targets: unittests
        task_compile_flags: >-
          --detect-odr-violations

## unittests - run unittests ##
- name: unittests
  commands:
    - func: "run diskstats"
    - func: "monitor process threads"
    - func: "collect system resource info"
    - func: "run tests"
      vars:
        resmoke_args: --suites=unittests

## compile_dbtest ##
- name: compile_dbtest
  commands:
    - func: "scons compile"
      vars:
        targets: dbtest
        task_compile_flags: >-
          --detect-odr-violations

    # Tar unstripped dbtest, to be archived in case of failure
    - command: archive.targz_pack
      params:
        target: "dbtest_unstripped.tgz"
        source_dir: "src"
        include:
          - "./dbtest*"

## dbtest ##
- name: dbtest
  commands:
    - func: "run diskstats"
    - func: "monitor process threads"
    - func: "collect system resource info"
    - func: "run tests"
      vars:
        resmoke_args: --suites=dbtest --storageEngine=wiredTiger

## embedded_sdk_build_and_test_* - build the embedded-dev and embedded-test targets only ##

- name: embedded_sdk_build_cdriver
  commands:
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          VERSION=${version}
          WORKDIR=${workdir}

          rm -rf mongo-c-driver

          # NOTE: If you change the C Driver version here, also change the substitution in the CocoaPod podspec below in the apple builder.
          git clone --branch r1.13 --depth 1 https://github.com/mongodb/mongo-c-driver.git
          cd mongo-c-driver

          # Fixup VERSION so we don't end up with -dev on it. Remove this once we are building a stable version and CDRIVER-2861 is resolved.
          cp -f VERSION_RELEASED VERSION_CURRENT

          trap "cat CMakeFiles/CMakeOutput.log" EXIT
          export ${compile_env|}
          ${cmake_path|/opt/cmake/bin/cmake} -DCMAKE_INSTALL_PREFIX=$WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp -DENABLE_SHM_COUNTERS=OFF -DENABLE_SNAPPY=OFF -DENABLE_AUTOMATIC_INIT_AND_CLEANUP=OFF -DENABLE_TESTS=OFF -DENABLE_EXAMPLES=OFF -DENABLE_STATIC=OFF -DCMAKE_OSX_DEPLOYMENT_TARGET=${cdriver_cmake_osx_deployment_target|} ${cdriver_cmake_flags}
          make install VERBOSE=1

          # TODO: Remove this when we upgrade to a version of the C driver that has CDRIVER-2854 fixed.
          mkdir -p $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/share/doc/mongo-c-driver
          cp COPYING $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/share/doc/mongo-c-driver
          cp THIRD_PARTY_NOTICES $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/share/doc/mongo-c-driver
          if [ -d $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks ]; then

              # We need to account for the fact that on the Darwin
              # mobile platforms, things shouldn't go to the Resources
              # directory but on macOS they should. If the Resources
              # directory is there (it should be for the plist file),
              # then use it, otherwise just use the framework root.
              if [ -e $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework/Resources ]; then
                  cp COPYING $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework/Resources
                  cp THIRD_PARTY_NOTICES $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework/Resources
                  plutil -insert MinimumOSVersion -string ${cdriver_cmake_osx_deployment_target} $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework/Resources/Info.plist
              else
                  cp COPYING $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework
                  cp THIRD_PARTY_NOTICES $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework
                  plutil -insert MinimumOSVersion -string ${cdriver_cmake_osx_deployment_target} $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/mongoc.framework/Info.plist
              fi

              if [ -e $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework/Resources ]; then
                  cp COPYING $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework/Resources
                  cp THIRD_PARTY_NOTICES $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework/Resources
                  plutil -insert MinimumOSVersion -string ${cdriver_cmake_osx_deployment_target} $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework/Resources/Info.plist
              else
                  cp COPYING $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework
                  cp THIRD_PARTY_NOTICES $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework
                  plutil -insert MinimumOSVersion -string ${cdriver_cmake_osx_deployment_target} $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks/bson.framework/Info.plist
              fi

          fi

          # CMake doesn't seem to do the dSYM for us for the framework
          if [ -e $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks ]; then
              pushd $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp/Frameworks
              xcrun dsymutil -o bson.framework.dSYM bson.framework/bson
              xcrun strip -Sx bson.framework/bson
              xcrun dsymutil -o mongoc.framework.dSYM mongoc.framework/mongoc
              xcrun strip -Sx mongoc.framework/mongoc
              popd
          fi

          mv $WORKDIR/src/build/mongo-embedded-sdk-$VERSION-tmp $WORKDIR/src/build/mongo-embedded-sdk-$VERSION

- name: embedded_sdk_install_dev
  commands:
    - func: "scons compile"
      vars:
        targets: install-embedded-dev
        task_compile_flags: &embedded_sdk_compile_flags >-
          --install-mode=hygienic
          --js-engine=none
          --prefix='$BUILD_ROOT/mongo-embedded-sdk-$MONGO_VERSION'
          --dbg=off
          --opt=size
          --enable-free-mon=off
          --ssl=off
          --enable-http-client=off
          --use-system-mongo-c=on
          --wiredtiger=off
          --allocator=system
          --separate-debug
          CPPPATH='$BUILD_ROOT/mongo-embedded-sdk-$MONGO_VERSION/include/libbson-1.0 $BUILD_ROOT/mongo-embedded-sdk-$MONGO_VERSION/include/libmongoc-1.0'
        task_compile_flags_extra: >-
          --link-model=dynamic-sdk

    # Unfortunately, it is very hard to get the symbol map filename
    # correct in SCons. We work around that here by letting SCons give
    # them a well known name, and then renaming them appropriately
    # once we have finished the build.
    - command: shell.exec
      params:
        working_dir: "src/build"
        script: |
          set -o errexit
          set -o verbose

          cd mongo-embedded-sdk-${version}

          if [ -e Frameworks/mongo_embedded.framework/BCSymbolMaps ]; then
              pushd Frameworks/mongo_embedded.framework
              mv BCSymbolMaps/libmongo_embedded.dylib.bcsymbolmap BCSymbolMaps/$(dwarfdump -u mongo_embedded | awk '{ print $2 }').bcsymbolmap
              popd
          fi

          if [ -e Frameworks/mongoc_embedded.framework/BCSymbolMaps ]; then
              pushd Frameworks/mongoc_embedded.framework
              mv BCSymbolMaps/libmongoc_embedded.dylib.bcsymbolmap BCSymbolMaps/$(dwarfdump -u mongoc_embedded | awk '{ print $2 }').bcsymbolmap
              popd
          fi

- name: embedded_sdk_s3_put
  commands:
    # Not using archive.targz_pack here because I can't get it to work.
    - command: shell.exec
      params:
        working_dir: "src/build"
        script: |
          set -o errexit
          set -o verbose

          cat <<EOF > mongo-embedded-sdk-${version}/README-Licenses.txt
          The software accompanying this file is Copyright (C) 2018 MongoDB, Inc. and
          is licensed to you on the terms set forth in the following files:
            - mongo-c-driver: share/doc/mongo-c-driver/COPYING
            - mongo_embedded: share/doc/mongo_embedded/LICENSE-Embedded.txt
            - mongoc_embedded: share/doc/mongo_embedded/LICENSE-Embedded.txt
          EOF

          tar cfvz embedded-sdk.tgz mongo-embedded-sdk-${version}

    # Upload it so we can download from EVG.
    - command: s3.put
      params:
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/embedded-sdk.tgz"
        remote_file: ${project}/embedded-sdk/${build_variant}/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "Embedded SDK Tar Archive"

- name: embedded_sdk_install_tests
  commands:
    - func: "scons compile"
      vars:
        targets: install-embedded-test
        task_compile_flags: *embedded_sdk_compile_flags
        task_compile_flags_extra: >-
          --link-model=dynamic

- name: embedded_sdk_tests_s3_put
  commands:
    # Not using archive.targz_pack here because I can't get it to work.
    - command: shell.exec
      params:
        working_dir: "src/build"
        script: |
          set -o errexit
          set -o verbose

          tar cfvz embedded-sdk-tests.tgz mongo-embedded-sdk-${version}

    # Upload it so we can download from EVG.
    - command: s3.put
      params:
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/embedded-sdk-tests.tgz"
        remote_file: ${project}/embedded-sdk-test/${build_variant}/${revision}/mongo-embedded-sdk-test-${version}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "Embedded SDK Tests Tar Archive"

- name: embedded_sdk_run_tests
  commands:
    - command: shell.exec
      params:
        working_dir: "src/build/mongo-embedded-sdk-${version}"
        script: |
          set -o errexit
          set -o verbose

          if [ ${enable_embedded_tests|false} = "ios_tvos_simulator" -a $(command -v xcrun) ]; then
            find ./lib -type f -name "*.dylib" -print0 | xargs -0 -L 1 xcrun codesign -s -
            find ./Frameworks -type f -name "*" '!' -name "*.*" -print0 | xargs -0 -L 1 xcrun codesign -s -
          fi

    - command: shell.exec
      type: test
      params:
        working_dir: src
        script: |
          set -o verbose
          set -o errexit

          ${activate_virtualenv}
          if [ ${enable_embedded_tests|false} = "ios_tvos_simulator" ]; then
              ${compile_env|} buildscripts/runiossim.sh ${ios_sim_device} ${ios_sim_runtime} "build/mongo-embedded-sdk-${version}/bin/mongo_embedded_test" --tempPath /data
              ${compile_env|} buildscripts/runiossim.sh ${ios_sim_device} ${ios_sim_runtime} "build/mongo-embedded-sdk-${version}/bin/mongoc_embedded_test" --tempPath /data
          elif [ ${enable_embedded_tests|false} = "android_emulator" ]; then
              cp -r build/mongo-embedded-sdk-${version} build/mongo-embedded-sdk-${version}-exec
              find build/mongo-embedded-sdk-${version}-exec/bin build/mongo-embedded-sdk-${version}-exec/lib -type f -name "*.debug" -delete
              ${compile_env|} buildscripts/runandroidsim.sh $(dirname $(pwd))/android_sdk ${android_toolchain_system_image_arch} ${android_system_image_version} "build/mongo-embedded-sdk-${version}-exec" "bin/mongo_embedded_test" --tempPath /data
              ${compile_env|} buildscripts/runandroidsim.sh $(dirname $(pwd))/android_sdk ${android_toolchain_system_image_arch} ${android_system_image_version} "build/mongo-embedded-sdk-${version}-exec" "bin/mongoc_embedded_test" --tempPath /data
          elif [ ${enable_embedded_tests|false} = "native" ]; then
            "build/mongo-embedded-sdk-${version}/bin/mongo_embedded_test"
            "build/mongo-embedded-sdk-${version}/bin/mongoc_embedded_test"
          fi

    # If this is a patch build, blow away the file so our subsequent and optional s3.put
    # doesn't run. That way, we won't overwrite the latest part in our patches.
    - command: shell.exec
      params:
        working_dir: "src/build"
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ]; then
            rm -f src/build/embedded-sdk.tgz
          fi

- name: embedded_sdk_s3_put_latest
  commands:
    # A second put, this time to -latest, to give devs a reasonable
    # way to get the most recent build.
    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/embedded-sdk.tgz"
        remote_file: ${project}/embedded-sdk/mongo-${build_variant}-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}

- name: embedded_sdk_tests_s3_put_latest
  commands:
    # A second put, this time to -latest, to give devs a reasonable
    # way to get the most recent build.
    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/embedded-sdk-tests.tgz"
        remote_file: ${project}/embedded-sdk-test/mongo-${build_variant}-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}

- name: embedded_sdk_multiarch_android_package
  depends_on:
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-android-arm32
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-android-arm64
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-android-x86_64
  commands:
    - command: manifest.load
    - func: "git get project"
    - func: "get buildnumber"
    - func: "set up credentials"
    - func: "setup android toolchain" # noop if ${setup_android_toolchain} is not "true"
    - func: "install pip requirements"
    - func: "generate compile expansions"
    - func: "apply compile expansions"
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-android-arm32/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "embedded-sdk-android-armeabi-v7a.tgz"
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-android-arm64/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "embedded-sdk-android-arm64-v8a.tgz"
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-android-x86_64/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "embedded-sdk-android-x86_64.tgz"
    - func: "setup gradle signing keys"
    - func: "build java embedded sdk"
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          if [ "${setup_android_toolchain|}" = "true" ]; then
            cd src/build
            tar zcvf mongo-embedded-sdk-${version}.tgz mongo-embedded-sdk-${version}
          fi
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/mongo-embedded-sdk-${version}.tgz"
        remote_file: "${project}/embedded-sdk/embedded-sdk-android-multiarch/${revision}/mongo-embedded-sdk-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "Embedded SDK Tar Archive"

    # If this is a patch build, blow away the file so our subsequent and optional s3.put
    # doesn't run. That way, we won't overwrite the latest part in our patches.
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ]; then
            rm -f src/build/mongo-embedded-sdk-${version}.tgz
          fi
    # A second put, this time to -latest, to give devs a reasonable
    # way to get the most recent build.
    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/mongo-embedded-sdk-${version}.tgz"
        remote_file: ${project}/embedded-sdk/mongo-${build_variant}-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar

- name: embedded_sdk_multiarch_java_package
  depends_on:
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-ubuntu-1604-x86_64
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-macos
  commands:
    - command: manifest.load
    - func: "git get project"
    - func: "get buildnumber"
    - func: "set up credentials"
    - func: "setup android toolchain" # noop if ${setup_android_toolchain} is not "true"
    - func: "install pip requirements"
    - func: "generate compile expansions"
    - func: "apply compile expansions"
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-ubuntu-1604-x86_64/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "embedded-sdk-java-linux-x86-64.tgz"
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-macos/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "embedded-sdk-java-darwin.tgz"
    - func: "setup gradle signing keys"
    - func: "build java embedded sdk"
      vars:
        package_type: embedded-jar
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          if [ "${setup_android_toolchain|}" = "true" ]; then
            cd src/build
            tar zcvf mongo-embedded-sdk-${version}.tgz mongo-embedded-sdk-${version}
          fi
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/mongo-embedded-sdk-${version}.tgz"
        remote_file: "${project}/embedded-sdk/embedded-sdk-java-multiarch/${revision}/mongo-embedded-sdk-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "Embedded SDK Tar Archive"
    # If this is a patch build, blow away the file so our subsequent and optional s3.put
    # doesn't run. That way, we won't overwrite the latest part in our patches.
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ]; then
            rm -f src/build/mongo-embedded-sdk-${version}.tgz
          fi
    # A second put, this time to -latest, to give devs a reasonable
    # way to get the most recent build.
    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/mongo-embedded-sdk-${version}.tgz"
        remote_file: ${project}/embedded-sdk/mongo-${build_variant}-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar


- name: embedded_sdk_multiarch_apple_package
  depends_on:
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-macos
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-iphoneos
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-iphonesimulator
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-appletvos
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-appletvsimulator
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-watchos
    - name: embedded_sdk_s3_put
      variant: embedded-sdk-watchsimulator

  commands:
    - command: manifest.load
    - func: "git get project"
    - func: "get buildnumber"
    - func: "set up credentials"
    - func: "install pip requirements"
    - func: "generate compile expansions"
    - func: "apply compile expansions"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-macos/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/MacOS/embedded-sdk.tgz"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-iphoneos/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/iPhoneOS/embedded-sdk.tgz"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-iphonesimulator/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/iPhoneSimulator/embedded-sdk.tgz"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-appletvos/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/AppleTVOS/embedded-sdk.tgz"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-appletvsimulator/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/AppleTVSimulator/embedded-sdk.tgz"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-watchos/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/WatchOS/embedded-sdk.tgz"

    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/embedded-sdk/embedded-sdk-watchsimulator/${revision}/mongo-embedded-sdk-${version}.tgz
        bucket: mciuploads
        local_file: "mongo-embedded-sdk-${version}/WatchSimulator/embedded-sdk.tgz"

    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          pushd mongo-embedded-sdk-${version}

          for directory in *OS *Simulator; do
              pushd $directory
              tar --include "*/Frameworks/*" --strip-components=1 -xf ./embedded-sdk.tgz
              popd
          done

          for platform in iPhone AppleTV Watch; do
              for framework in bson mongoc mongo_embedded mongoc_embedded; do
                  _OSFile=$(printf ./%sOS/Frameworks/%s.framework/%s $platform $framework $framework)
                  _SimulatorFile=$(printf ./%sSimulator/Frameworks/%s.framework/%s $platform $framework $framework)
                  ${compile_env|} xcrun lipo $_OSFile $_SimulatorFile -create -output $_OSFile
              done
          done

          for platform in iPhone AppleTV Watch; do
              for framework in bson mongoc; do
                  _OSDSYM=$(printf ./%sOS/Frameworks/%s.framework.dSYM/Contents/Resources/DWARF/%s $platform $framework $framework)
                  _SimulatorDSYM=$(printf ./%sSimulator/Frameworks/%s.framework.dSYM/Contents/Resources/DWARF/%s $platform $framework $framework)
                  ${compile_env|} xcrun lipo $_OSDSYM $_SimulatorDSYM -create -output $_OSDSYM
              done

              for framework in mongo_embedded mongoc_embedded; do
                  _OSDSYM=$(printf ./%sOS/Frameworks/%s.framework.dSYM/Contents/Resources/DWARF/lib%s.dylib $platform $framework $framework)
                  _SimulatorDSYM=$(printf ./%sSimulator/Frameworks/%s.framework.dSYM/Contents/Resources/DWARF/lib%s.dylib $platform $framework $framework)
                  ${compile_env|} xcrun lipo $_OSDSYM $_SimulatorDSYM -create -output $_OSDSYM
              done
          done

          for platform in iPhone AppleTV Watch; do
              for framework in mongo_embedded mongoc_embedded; do
                  _OSBCSymbolMaps=$(printf ./%sOS/Frameworks/%s.framework/BCSymbolMaps $platform $framework)
                  _SimulatorBCSymbolMaps=$(printf ./%sSimulator/Frameworks/%s.framework/BCSymbolMaps $platform $framework)
                  if [ -e $_SimulatorBCSymbolMaps -a -e $_OSBCSymbolMaps ]; then
                      cp $_SimulatorBCSymbolMaps/* $_OSBCSymbolMaps/
                  fi
              done
          done

          popd

          cat <<EOF > mongo-embedded-sdk-${version}/README-Licenses.txt
          The software accompanying this file is Copyright (C) 2018 MongoDB, Inc. and
          is licensed to you on the terms set forth in the following files:
            - mongo-c-driver: iPhoneOS/Frameworks/mongoc.framework/COPYING
            - mongo_embedded: iPhoneOS/Frameworks/mongo_embedded.framework/LICENSE-Embedded.txt
            - mongoc_embedded: iPhoneOS/Frameworks/mongoc_embedded.framework/LICENSE-Embedded.txt
          EOF
          tar --exclude "mongo-embedded-sdk-${version}/*/*.tgz" -zcvf mongo-embedded-sdk-${version}.tgz \
              ./mongo-embedded-sdk-${version}/*OS \
              ./mongo-embedded-sdk-${version}/README-Licenses.txt

          cat <<EOF > mongo-embedded-sdk-${version}/README-Licenses.txt
          The software accompanying this file is Copyright (C) 2018 MongoDB, Inc. and
          is licensed to you on the terms set forth in the following files:
            - mongo-c-driver: iPhoneOS/Frameworks/mongoc.framework/COPYING
          EOF
          tar --exclude "mongo-embedded-sdk-${version}/*/*.tgz" -zcvf mongo-embedded-sdk-${version}-mongo-c-driver.tgz \
              ./mongo-embedded-sdk-${version}/*OS/Frameworks/bson.framework{,.dSYM} \
              ./mongo-embedded-sdk-${version}/*OS/Frameworks/mongoc.framework{,.dSYM} \
              ./mongo-embedded-sdk-${version}/README-Licenses.txt

          cat <<EOF > mongo-embedded-sdk-${version}/README-Licenses.txt
          The software accompanying this file is Copyright (C) 2018 MongoDB, Inc. and
          is licensed to you on the terms set forth in the following files:
            - mongo_embedded: iPhoneOS/Frameworks/mongo_embedded.framework/LICENSE-Embedded.txt
          EOF
          tar --exclude "mongo-embedded-sdk-${version}/*/*.tgz" -zcvf mongo-embedded-sdk-${version}-mongo-embedded.tgz \
              ./mongo-embedded-sdk-${version}/*OS/Frameworks/mongo_embedded.framework{,.dSYM} \
              ./mongo-embedded-sdk-${version}/README-Licenses.txt

          cat <<EOF > mongo-embedded-sdk-${version}/README-Licenses.txt
          The software accompanying this file is Copyright (C) 2018 MongoDB, Inc. and
          is licensed to you on the terms set forth in the following files:
            - mongoc_embedded: iPhoneOS/Frameworks/mongoc_embedded.framework/LICENSE-Embedded.txt
          EOF
          tar --exclude "mongo-embedded-sdk-${version}/*/*.tgz" -zcvf mongo-embedded-sdk-${version}-mongoc-embedded.tgz \
              ./mongo-embedded-sdk-${version}/*OS/Frameworks/mongoc_embedded.framework{,.dSYM} \
              ./mongo-embedded-sdk-${version}/README-Licenses.txt

    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}.tgz"
        remote_file: "${project}/embedded-sdk/embedded-sdk-apple-multiarch/${revision}/mongo-embedded-sdk-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "Embedded SDK Tar Archive"

    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongo-c-driver.tgz"
        remote_file: "${project}/embedded-sdk/mongo-c-driver-apple-multiarch/${revision}/mongo-embedded-sdk-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "MongoDB C Driver Tar Archive"

    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongo-embedded.tgz"
        remote_file: "${project}/embedded-sdk/mongo-embedded-apple-multiarch/${revision}/mongo-embedded-sdk-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "MongoDB Embedded Tar Archive"

    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongoc-embedded.tgz"
        remote_file: "${project}/embedded-sdk/mongoc-embedded-apple-multiarch/${revision}/mongo-embedded-sdk-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "MongoDB Embedded C Driver Transport Tar Archive"

    # If this is a patch build, blow away the file so our subsequent and optional s3.put
    # doesn't run. That way, we won't overwrite the latest part in our patches.
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_patch}" = "true" ]; then
            rm -f mongo-embedded-sdk-${version}.tgz
            rm -f mongo-embedded-sdk-${version}-mongo-c-driver.tgz
            rm -f mongo-embedded-sdk-${version}-mongo-embedded.tgz
            rm -f mongo-embedded-sdk-${version}-mongoc-embedded.tgz
          fi

    # A second put, this time to -latest, to give devs a reasonable
    # way to get the most recent build.
    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}.tgz"
        remote_file: ${project}/embedded-sdk/mongo-${build_variant}-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongo-c-driver.tgz"
        remote_file: ${project}/embedded-sdk/mongo-c-driver-cocoapod-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongo-embedded.tgz"
        remote_file: ${project}/embedded-sdk/mongo-embedded-cocoapod-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongoc-embedded.tgz"
        remote_file: ${project}/embedded-sdk/mongoc-embedded-cocoapod-latest.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar

    # If this is not a release build, blow away the file so our subsequent and optional s3.put
    # doesn't run. That way, we won't overwrite the latest part in our patches.
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          if [ "${is_release}" != "true" ]; then
            rm -f mongo-embedded-sdk-${version}.tgz
            rm -f mongo-embedded-sdk-${version}-mongo-c-driver.tgz
            rm -f mongo-embedded-sdk-${version}-mongo-embedded.tgz
            rm -f mongo-embedded-sdk-${version}-mongoc-embedded.tgz
          fi

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}.tgz"
        remote_file: ${push_path}-STAGE/${push_name}/mongo-${build_variant}-${version}.tgz
        bucket: build-push-testing
        permissions: public-read
        content_type: application/tar

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongo-c-driver.tgz"
        remote_file: ${push_path}-STAGE/${push_name}/mongo-c-driver-${version}.tgz
        bucket: build-push-testing
        permissions: public-read
        content_type: application/tar

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongo-embedded.tgz"
        remote_file: ${push_path}-STAGE/${push_name}/mongo-embedded-${version}.tgz
        bucket: build-push-testing
        permissions: public-read
        content_type: application/tar

    - command: s3.put
      params:
        visibility: none
        optional: true
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "mongo-embedded-sdk-${version}-mongoc-embedded.tgz"
        remote_file: ${push_path}-STAGE/${push_name}/mongoc-embedded-${version}.tgz
        bucket: build-push-testing
        permissions: public-read
        content_type: application/tar

    - command: s3Copy.copy
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        optional: true
        s3_copy_files:
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongoc-embedded-${version}.tgz', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/${push_name}/mongoc-embedded-${version}.tgz', 'bucket': '${push_bucket}'}}

            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongo-embedded-${version}.tgz', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/${push_name}/mongo-embedded-${version}.tgz', 'bucket': '${push_bucket}'}}

            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongo-c-driver-${version}.tgz', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/${push_name}/mongo-c-driver-${version}.tgz', 'bucket': '${push_bucket}'}}

    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose

          echo "Releases disabled on master."
          exit 0

          if [ "${is_release|false}" != "true" ]; then
              echo "Not a release build"
              exit 0 
          fi

          sed s/@VERSION@/1.13.0/g src/src/mongo/embedded/mongoc_embedded/mongo-embedded-c-driver.podspec.in | tee mongo-embedded-c-driver.podspec
          DRIVER_SHA=`shasum -a 256 mongo-embedded-sdk-${version}-mongo-c-driver.tgz  | awk '{ print $1 }'`
          sed -i '' s/@SHA256@/$DRIVER_SHA/g mongo-embedded-c-driver.podspec
          sed -i '' s/@MONGO_VERSION@/${version}/g mongo-embedded-c-driver.podspec

          sed s/@VERSION@/${version}/g src/src/mongo/embedded/mongo_embedded/mongo_embedded.podspec.in | tee mongo_embedded.podspec
          MONGO_SHA=`shasum -a 256 mongo-embedded-sdk-${version}-mongo-embedded.tgz  | awk '{ print $1 }'`
          sed -i '' s/@SHA256@/$MONGO_SHA/g mongo_embedded.podspec

          sed s/@VERSION@/${version}/g src/src/mongo/embedded/mongoc_embedded/mongoc_embedded.podspec.in | tee mongoc_embedded.podspec
          MONGOC_SHA=`shasum -a 256 mongo-embedded-sdk-${version}-mongoc-embedded.tgz  | awk '{ print $1 }'`
          sed -i '' s/@SHA256@/$MONGOC_SHA/g mongoc_embedded.podspec

          pod trunk push mongo-embedded-c-driver.podspec
          pod trunk push mongo_embedded.podspec
          pod trunk push mongoc_embedded.podspec

- name: stitch_support_create_lib
  commands:
    - func: "scons compile"
      vars:
        targets: install-stitch-support
        task_compile_flags: >-
          --install-mode=hygienic
          --prefix='$BUILD_ROOT/stitch-support-lib-$MONGO_VERSION'
          --dbg=off
          --link-model=dynamic-sdk
    - command: shell.exec
      params:
        working_dir: "src/build"
        script: |
          set -o errexit
          set -o verbose

          tar cfvz stitch-support.tgz stitch-support-lib-${version}
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: "src/build/stitch-support.tgz"
        remote_file: "${project}/stitch-support/${build_variant}/${revision}/stitch-support-${version}.tgz"
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: "Stitch Support Library"

- name: stitch_support_install_tests
  commands:
    - func: "scons compile"
      vars:
        targets: install-stitch-support-test
        task_compile_flags: >-
          --install-mode=hygienic
          --prefix='$BUILD_ROOT/stitch-support-lib-$MONGO_VERSION'
          --dbg=off

- name: stitch_support_run_tests
  commands:
    - command: shell.exec
      type: test
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          "build/stitch-support-lib-${version}/bin/stitch_support_test"

- name: compile_benchmarks
  depends_on: []
  commands:
    - command: manifest.load
    - func: "git get project"
    - func: "get buildnumber"
    - func: "set up credentials"
    - func: "use WiredTiger develop" # noop if ${use_wt_develop} is not "true"
    - func: "install pip requirements"
    - func: "generate compile expansions"
    # Then we load the generated version data into the agent so we can use it in task definitions
    - func: "apply compile expansions"
    - func: "scons compile"
      vars:
        targets: benchmarks
    - command: archive.targz_pack
      params:
        target: "benchmarks.tgz"
        source_dir: "src"
        include:
          - "./build/benchmarks.txt"
          - "./build/**_bm"
          - "./build/**_bm.gcno"
          - "./build/**_bm.exe"
          - "./build/**_bm.pdb"
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: benchmarks.tgz
        remote_file: ${project}/${build_variant}/${revision}/benchmarks/${build_id}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/tar
        display_name: Benchmarks

## lint ##
- name: lint
  depends_on: []
  commands:
    - command: manifest.load
    - func: "git get project"
    - command: shell.exec
      type: test
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          ${activate_virtualenv}
          python3 -m pip install -I -r etc/pip/lint-requirements.txt
          python2 -m pip install -I -r etc/pip/lint-requirements.txt
          export MYPY="$(
            if command -V cygpath 2>/dev/null; then
                PATH+=":$(cypath "${workdir}")/venv_3/Scripts"
            else
                PATH+=":${workdir}/venv_3/bin"
            fi
            PATH+=':/opt/mongodbtoolchain/v3/bin'
            which mypy
          )"
          echo "Found mypy executable at '$MYPY'"
          ${compile_env|} python2 ./buildscripts/scons.py ${compile_flags|} --stack-size=1024 lint

- name: verify_pip
  depends_on: []
  commands:
  - command: manifest.load
  - func: "git get project"
  - command: shell.exec
    type: test
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        # Note: One pleasant side effect of this task is that it should pre warm pip's cache.
        # For every pypa project that is part of our current toolchain, this will do nothing.
        # For every pypa project that we are missing, the .whl file will be added to the pip cache.
        # (See https://pip.pypa.io/en/latest/reference/pip_install/#caching)

        ${activate_virtualenv}
        # This installs the explicit project versions which would be installed in the toolchain
        # from this patch
        python2 -m pip install -I -r etc/pip/constraints.txt
        python3 -m pip install -I -r etc/pip/constraints.txt

        python2 -m pip freeze >requirements.txt.python2.old
        python3 -m pip freeze >requirements.txt.python3.old

        # This installs any requirements which are unsatisfied by the constraints.txt above
        python2 -m pip install -r etc/pip/toolchain-requirements.txt
        python3 -m pip install -r etc/pip/toolchain-requirements.txt

        python2 -m pip freeze >requirements.txt.python2.new
        python3 -m pip freeze >requirements.txt.python3.new

        # Compare the old freezes to the new freezes.
        # They should be the same if our constraints satisfy our toolchain requirements
        diff -w requirements.txt.python2.old requirements.txt.python2.new
        diff -w requirements.txt.python3.old requirements.txt.python3.new

- <<: *task_template
  name: burn_in_tests
  depends_on:
  - name: compile
  commands:
  - func: "git get project"
    # The repository is cloned in a directory distinct from src for the modified test detection
    # because the extraction of the artifacts performed in the 'do setup' causes
    # 'git diff --name-only' to see all tests as modified on Windows (git 1.9.5). See SERVER-30634.
    vars:
      git_project_directory: burn_in_tests_clonedir
  - func: "do setup"
  - command: shell.exec
    params:
      working_dir: burn_in_tests_clonedir
      shell: bash
      script: |
        set -o errexit
        set -o verbose
        # If this is a scheduled build, we check for changes against the last scheduled commit.
        if [ "${is_patch}" != "true" ]; then
          burn_in_args="--checkEvergreen"
        fi
        # Copy the dbtest executable from the src dir because burn_in_tests.py calls it to get the
        # list of dbtest suites.
        cp ../src/dbtest${exe} .
        pushd ../src
        ${activate_virtualenv}
        popd
        # Capture a list of new and modified tests.
        build_variant=${build_variant}
        if [ -n "${burn_in_tests_build_variant|}" ]; then
          build_variant=${burn_in_tests_build_variant|}
        fi
        # Evergreen executable is in $HOME.
        PATH=$PATH:$HOME $python buildscripts/burn_in_tests.py --branch=${branch_name} --buildVariant=$build_variant --testListOutfile=jstests/new_tests.json --noExec $burn_in_args
        # Copy the results to the src dir.
        cp jstests/new_tests.json ../src/jstests/new_tests.json
  - func: "do multiversion setup"
  - func: "run tests"
    vars:
      task_path_suffix: /data/multiversion:$HOME
      resmoke_wrapper: $python buildscripts/burn_in_tests.py --testListFile=jstests/new_tests.json
      resmoke_args: --repeatSuites=2

- <<: *benchmark_template
  name: benchmarks_orphaned
  commands:
  - func: "do benchmark setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchmarks
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchmark_template
  name: benchmarks_sharding
  commands:
  - func: "do benchmark setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchmarks_sharding
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *task_template
  name: generate_benchrun_embedded_files
  commands:
  - func: "git get project"
  - func: "fetch binaries"
  - func: "extract binaries"
  - command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        ${activate_virtualenv}

        mkdir -p /data/db
        rm -rf /data/db/*

        ./mongod --fork --logpath=/data/db/mongod.log
        PATH="$(pwd):$PATH" ./src/third_party/scripts/mongo-perf_get_sources.sh
        ./mongo --eval 'db.getSiblingDB("admin").shutdownServer()'
  - command: archive.targz_pack
    params:
      target: "src/benchrun_json_files.tgz"
      source_dir: "${workdir}/src/benchrun_embedded/testcases"
      include:
      - "**.json"
  - command: s3.put
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      local_file: src/benchrun_json_files.tgz
      remote_file: ${project}/${build_variant}/${revision}/benchrun_json_files.tgz
      bucket: mciuploads
      permissions: public-read
      content_type: ${content_type|application/gzip}
      display_name: benchrun embedded JSON config files

- <<: *task_template
  name: upload_benchrun_embedded_files
  depends_on:
  - generate_benchrun_embedded_files
  patchable: false
  commands:
  - command: s3Copy.copy
    params:
      aws_key: ${aws_key}
      aws_secret: ${aws_secret}
      s3_copy_files:
      - source:
          path: ${project}/${build_variant}/${revision}/benchrun_json_files.tgz
          bucket: mciuploads
        destination:
          path: ${project}/benchrun_embedded/benchrun_json_files.tgz
          bucket: mciuploads
        build_variants: [rhel-62-64-bit-mobile]

- <<: *benchrun_embedded_template
  name: benchrun_embedded_aggregation
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_aggregation
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_commands
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_commands
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_insert
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_insert
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_misc
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_misc
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_mixed_and_multi
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_mixed_and_multi
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_queries
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_queries
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_remove
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_remove
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *benchrun_embedded_template
  name: benchrun_embedded_update
  commands:
  - func: "do benchmark embedded setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=benchrun_embedded_update
      resmoke_jobs_max: 1
  - func: "send benchmark results"

- <<: *run_jepsen_template
  name: jepsen_register_findAndModify
  commands:
  - func: "do setup"
  - func: "do jepsen setup"
  - func: "run jepsen test"
    vars:
      <<: *jepsen_config_vars
      jepsen_read_with_find_and_modify: --read-with-find-and-modify
      jepsen_storage_engine: --storage-engine wiredTiger
      jepsen_test_name: register

- <<: *run_jepsen_template
  name: jepsen_register_linearizableRead
  commands:
  - func: "do setup"
  - func: "do jepsen setup"
  - func: "run jepsen test"
    vars:
      <<: *jepsen_config_vars
      jepsen_read_concern: --read-concern linearizable
      jepsen_storage_engine: --storage-engine wiredTiger
      jepsen_test_name: register

- <<: *run_jepsen_template
  name: jepsen_set_linearizableRead
  commands:
  - func: "do setup"
  - func: "do jepsen setup"
  - func: "run jepsen test"
    vars:
      <<: *jepsen_config_vars
      jepsen_read_concern: --read-concern linearizable
      jepsen_storage_engine: --storage-engine wiredTiger
      jepsen_test_name: set

- <<: *run_jepsen_template
  name: jepsen_read-concern-majority
  commands:
  - func: "do setup"
  - func: "do jepsen setup"
  - func: "run jepsen test"
    vars:
      <<: *jepsen_config_vars
      jepsen_storage_engine: --storage-engine wiredTiger
      jepsen_test_name: read-concern-majority

- <<: *run_jepsen_template
  name: jepsen_read-concern-majority_w1
  commands:
  - func: "do setup"
  - func: "do jepsen setup"
  - func: "run jepsen test"
    vars:
      <<: *jepsen_config_vars
      jepsen_storage_engine: --storage-engine wiredTiger
      jepsen_test_name: read-concern-majority
      jepsen_write_concern: --write-concern w1

## Standalone generational fuzzer for aggregation pipelines ##
- <<: *jstestfuzz_template
  name: aggregation_multiversion_fuzzer_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 5
      num_tasks: 10
      resmoke_args: --suites=generational_fuzzer
      npm_command: agg-fuzzer
      name: aggregation_multiversion_fuzzer
      task_path_suffix: "/data/multiversion"

## Standalone generational fuzzer for aggregation expressions ##
- <<: *jstestfuzz_template
  name: aggregation_expression_multiversion_fuzzer_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 5
      num_tasks: 10
      resmoke_args: --suites=generational_fuzzer
      npm_command: agg-expr-fuzzer
      name: aggregation_expression_multiversion_fuzzer
      task_path_suffix: "/data/multiversion"

## Standalone fuzzer for checking wildcard index correctness ##
- <<: *jstestfuzz_template
  name: aggregation_wildcard_fuzzer_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 5
      num_tasks: 10
      jstestfuzz_vars: --diffTestingMode wildcard
      npm_command: agg-fuzzer
      resmoke_args: --suites=generational_fuzzer
      name: aggregation_wildcard_fuzzer

## jstestfuzz standalone update generational fuzzer ##
- <<: *jstestfuzz_template
  name: update_fuzzer_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 5
      num_tasks: 10
      npm_command: update-fuzzer
      resmoke_args: --suites=generational_fuzzer
      name: update_fuzzer
      task_path_suffix: "/data/multiversion"

## jstestfuzz replication update generational fuzzer ##
- <<: *jstestfuzz_template
  name: update_fuzzer_replication_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 5
      num_tasks: 10
      npm_command: update-fuzzer
      resmoke_args: --suites=generational_fuzzer_replication
      name: update_fuzzer_replication
      task_path_suffix: "/data/multiversion"

## rollback generational fuzzer ##
- <<: *jstestfuzz_template
  name: rollback_fuzzer_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 3
      num_tasks: 5
      npm_command: rollback-fuzzer
      resmoke_args: --suites=rollback_fuzzer
      name: rollback_fuzzer

## rollback generational fuzzer with clean shutdowns ##
- <<: *jstestfuzz_template
  name: rollback_fuzzer_clean_shutdowns_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 1
      num_tasks: 4
      jstestfuzz_vars: --numLinesPerFile 300 --maxLinesBetweenEvents 50
      npm_command: rollback-fuzzer
      resmoke_args: --suites=rollback_fuzzer_clean_shutdowns
      name: rollback_fuzzer_clean_shutdowns

## rollback generational fuzzer with unclean shutdowns ##
- <<: *jstestfuzz_template
  name: rollback_fuzzer_unclean_shutdowns_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 1
      num_tasks: 4
      jstestfuzz_vars: --numLinesPerFile 300 --maxLinesBetweenEvents 50
      npm_command: rollback-fuzzer
      resmoke_args: --suites=rollback_fuzzer_unclean_shutdowns
      name: rollback_fuzzer_unclean_shutdowns

## jstestfuzz ##
- <<: *jstestfuzz_template
  name: jstestfuzz_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz --storageEngine=wiredTiger
      npm_command: jstestfuzz
      name: jstestfuzz

## jstestfuzz concurrent ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 15
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent

## jstestfuzz concurrent replica set ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_replication_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 15
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_replication --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent_replication

## jstestfuzz concurrent replica set with logical session ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_replication_session_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 15
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_replication_session --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent_replication_session

## jstestfuzz concurrent sharded cluster ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_sharded_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 15
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent_sharded

## jstestfuzz concurrent sharded cluster causal consistency ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_sharded_causal_consistency_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 15
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded_causal_consistency --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent_sharded_causal_consistency

## jstestfuzz concurrent sharded cluster continuous stepdown ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_sharded_continuous_stepdown_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 2
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded_continuous_stepdown --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent_sharded_continuous_stepdown

## jstestfuzz concurrent sharded cluster with logical session ##
- <<: *jstestfuzz_template
  name: jstestfuzz_concurrent_sharded_session_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: ${jstestfuzz_concurrent_num_files|10}
      num_tasks: 15
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded_session --storageEngine=wiredTiger --numClientsPerFixture=10
      name: jstestfuzz_concurrent_sharded_session

# jstestfuzz interrupt #
- <<: *jstestfuzz_template
  name: jstestfuzz_interrupt_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_interrupt --storageEngine=wiredTiger
      name: jstestfuzz_interrupt

# jstestfuzz interrupt #
- <<: *jstestfuzz_template
  name: jstestfuzz_interrupt_replication_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_interrupt_replication --storageEngine=wiredTiger
      name: jstestfuzz_interrupt_replication

## jstestfuzz replica set ##
- <<: *jstestfuzz_template
  name: jstestfuzz_replication_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_replication --storageEngine=wiredTiger
      name: jstestfuzz_replication

## jstestfuzz initial sync replica set ##
- <<: *jstestfuzz_template
  name: jstestfuzz_replication_initsync_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 8
      num_tasks: 10
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_replication_initsync --storageEngine=wiredTiger
      name: jstestfuzz_replication_initsync

## jstestfuzz replica set with logical session ##
- <<: *jstestfuzz_template
  name: jstestfuzz_replication_session_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_replication_session --storageEngine=wiredTiger
      name: jstestfuzz_replication_session

## jstestfuzz sharded cluster ##
- <<: *jstestfuzz_template
  name: jstestfuzz_sharded_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded --storageEngine=wiredTiger
      name: jstestfuzz_sharded

## jstestfuzz sharded cluster causal consistency ##
- <<: *jstestfuzz_template
  name: jstestfuzz_sharded_causal_consistency_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded_causal_consistency --storageEngine=wiredTiger
      name: jstestfuzz_sharded_causal_consistency

## jstestfuzz sharded cluster continuous stepdown ##
- <<: *jstestfuzz_template
  name: jstestfuzz_sharded_continuous_stepdown_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      num_files: 5
      num_tasks: 10
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded_continuous_stepdown --storageEngine=wiredTiger
      name: jstestfuzz_sharded_continuous_stepdown

## jstestfuzz sharded cluster with logical session ##
- <<: *jstestfuzz_template
  name: jstestfuzz_sharded_session_gen
  commands:
  - func: "generate fuzzer tasks"
    vars:
      <<: *jstestfuzz_config_vars
      jstestfuzz_vars: --jsTestsDir ../jstests
      resmoke_args: --suites=jstestfuzz_sharded_session --storageEngine=wiredTiger
      name: jstestfuzz_sharded_session

## integration test suites ##

- <<: *task_template
  name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_ese
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_ese --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_auth
  depends_on:
  - name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_auth --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_facet_unwind_passthrough
  depends_on:
  - name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_facet_unwind_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_mongos_passthrough
  depends_on:
  - name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_mongos_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_one_shard_sharded_collections
  depends_on:
  - name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_one_shard_sharded_collections --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_read_concern_majority_passthrough
  depends_on:
  - name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_read_concern_majority_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: aggregation_sharded_collections_passthrough
  depends_on:
  - name: aggregation
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=aggregation_sharded_collections_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: audit
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=audit --storageEngine=wiredTiger

- <<: *task_template
  name: auth
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=auth --storageEngine=wiredTiger

- <<: *task_template
  name: causally_consistent_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=causally_consistent_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: causally_consistent_jscore_passthrough_auth
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=causally_consistent_jscore_passthrough_auth --storageEngine=wiredTiger

- <<: *task_template
  name: sharded_causally_consistent_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=sharded_causally_consistent_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: logical_session_cache_sharding_1sec_refresh_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=logical_session_cache_sharding_1sec_refresh_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: logical_session_cache_replication_1sec_refresh_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=logical_session_cache_replication_1sec_refresh_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: logical_session_cache_standalone_1sec_refresh_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=logical_session_cache_standalone_1sec_refresh_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: multi_shard_multi_stmt_txn_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=multi_shard_multi_stmt_txn_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: multi_stmt_txn_jscore_passthrough_with_migration
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=multi_stmt_txn_jscore_passthrough_with_migration --storageEngine=wiredTiger

- <<: *task_template
  name: noPassthrough
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=no_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: noPassthroughWithMongod
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=no_passthrough_with_mongod --storageEngine=wiredTiger

- <<: *task_template
  name: read_concern_majority_passthrough
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=read_concern_majority_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: retryable_writes_jscore_passthrough
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=retryable_writes_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: ssl
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=ssl --storageEngine=wiredTiger

- <<: *task_template
  name: sslSpecial
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=ssl_special --storageEngine=wiredTiger

- <<: *task_template
  name: slow1
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=slow1 --storageEngine=wiredTiger

- <<: *task_template
  name: concurrency_sharded_causal_consistency
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=concurrency_sharded_causal_consistency --storageEngine=wiredTiger
        resmoke_jobs_max: 1

- <<: *task_template
  name: parallel
  depends_on:
  - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=parallel --storageEngine=wiredTiger
        resmoke_jobs_max: 1

- <<: *task_template
  name: replica_sets_multi_stmt_txn_stepdown_jscore_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=replica_sets_multi_stmt_txn_stepdown_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: sharded_causally_consistent_jscore_txns_passthrough
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=sharded_causally_consistent_jscore_txns_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: sharding_jscore_passthrough_wire_ops
  depends_on:
    - name: jsCore
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=sharding_jscore_passthrough --storageEngine=wiredTiger --shellReadMode=legacy --shellWriteMode=compatibility --excludeWithAnyTags=requires_find_command

- <<: *task_template
  name: auth_audit
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=auth_audit --storageEngine=wiredTiger

- <<: *task_template
  name: sharding_auth
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=sharding_auth --storageEngine=wiredTiger

- <<: *task_template
  name: sharding_auth_audit
  commands:
    - func: "do setup"
    - func: "run tests"
      vars:
        resmoke_args: --suites=sharding_auth_audit --storageEngine=wiredTiger

- name: auth_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: auth
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 4

- name: auth_audit_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: auth_audit
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 4

- <<: *task_template
  name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_mongos_sessions_passthrough
  depends_on:
  - name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_mongos_sessions_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_mongos_passthrough
  depends_on:
  - name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_mongos_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_secondary_reads
  depends_on:
  - name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_secondary_reads --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_sharded_collections_passthrough
  depends_on:
  - name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_sharded_collections_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_db_passthrough
  depends_on:
  - name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_db_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_db_mongos_passthrough
  depends_on:
  - name: change_streams_mongos_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_db_mongos_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_db_secondary_reads_passthrough
  depends_on:
  - name: change_streams_secondary_reads
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_db_secondary_reads_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_db_sharded_collections_passthrough
  depends_on:
  - name: change_streams_sharded_collections_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_db_sharded_collections_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_cluster_passthrough
  depends_on:
  - name: change_streams
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_cluster_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_cluster_mongos_passthrough
  depends_on:
  - name: change_streams_mongos_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_cluster_mongos_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_cluster_secondary_reads_passthrough
  depends_on:
  - name: change_streams_secondary_reads
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_cluster_secondary_reads_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: change_streams_whole_cluster_sharded_collections_passthrough
  depends_on:
  - name: change_streams_sharded_collections_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=change_streams_whole_cluster_sharded_collections_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: disk_mobile
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=disk_mobile --storageEngine=mobile
      resmoke_jobs_max: 1

- <<: *task_template
  name: disk_wiredtiger
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=disk_wiredtiger --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: ese
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=ese --storageEngine=wiredTiger

- <<: *task_template
  name: failpoints
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=failpoints --storageEngine=wiredTiger

- <<: *task_template
  name: failpoints_auth
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=failpoints_auth --storageEngine=wiredTiger

- <<: *task_template
  name: gle_auth
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=gle_auth --shellWriteMode=legacy --shellReadMode=legacy --excludeWithAnyTags=requires_find_command --storageEngine=wiredTiger

- <<: *task_template
  name: gle_auth_write_cmd
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=gle_auth --shellWriteMode=commands --storageEngine=wiredTiger

- <<: *task_template
  name: gle_auth_basics_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=gle_auth_basics_passthrough --shellWriteMode=legacy --shellReadMode=legacy --storageEngine=wiredTiger --excludeWithAnyTags=requires_find_command

- <<: *task_template
  name: gle_auth_basics_passthrough_write_cmd
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=gle_auth_basics_passthrough --shellWriteMode=commands --storageEngine=wiredTiger

- <<: *task_template
  name: integration_tests_standalone
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=integration_tests_standalone --storageEngine=wiredTiger

- <<: *task_template
  name: integration_tests_standalone_audit
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=integration_tests_standalone_audit --storageEngine=wiredTiger

- <<: *task_template
  name: integration_tests_replset
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=integration_tests_replset --storageEngine=wiredTiger

- <<: *task_template
  name: integration_tests_sharded
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=integration_tests_sharded --storageEngine=wiredTiger

- <<: *task_template
  name: external_auth
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=external_auth --storageEngine=wiredTiger

- <<: *task_template
  name: sharding_gle_auth_basics_passthrough
  depends_on:
  - name: gle_auth_basics_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharding_gle_auth_basics_passthrough --shellWriteMode=legacy --shellReadMode=legacy --storageEngine=wiredTiger --excludeWithAnyTags=requires_find_command

- <<: *task_template
  name: sharding_gle_auth_basics_passthrough_write_cmd
  depends_on:
  - name: gle_auth_basics_passthrough_write_cmd
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharding_gle_auth_basics_passthrough --shellWriteMode=commands --storageEngine=wiredTiger

- <<: *task_template
  name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core --storageEngine=wiredTiger

- <<: *task_template
  name: jsCore_mobile
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core --mongod=./mongoed --excludeWithAnyTags=requires_scripting,requires_auth,requires_sharding,does_not_support_stepdowns,requires_background_index,requires_ttl_index,incompatible_with_embedded,incompatible_with_embedded_todo_investigate,requires_replication,requires_capped,requires_profiling,requires_javascript,requires_fsync,requires_compact

- <<: *task_template
  name: jsCore_ese
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core_ese --storageEngine=wiredTiger

- <<: *task_template
  name: jsCore_compatibility
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core --shellReadMode=legacy --shellWriteMode=compatibility --storageEngine=wiredTiger --excludeWithAnyTags=requires_find_command

- <<: *task_template
  name: jsCore_auth
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core_auth

- <<: *task_template
  name: jsCore_minimum_batch_size
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core_minimum_batch_size --storageEngine=wiredTiger

- <<: *task_template
  name: jsCore_op_query
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core_op_query --storageEngine=wiredTiger

- <<: *task_template
  name: jsCore_txns
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=core_txns --storageEngine=wiredTiger

- <<: *task_template
  name: sharded_jscore_txns
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharded_jscore_txns --storageEngine=wiredTiger

- <<: *task_template
  name: sharded_jscore_txns_sharded_collections
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharded_jscore_txns_sharded_collections --storageEngine=wiredTiger

- <<: *task_template
  name: causally_consistent_jscore_txns_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=causally_consistent_jscore_txns_passthrough --storageEngine=wiredTiger

- name: sharded_causally_consistent_jscore_txns_passthrough_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharded_causally_consistent_jscore_txns_passthrough
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- <<: *task_template
  name: sharded_collections_causally_consistent_jscore_txns_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharded_collections_causally_consistent_jscore_txns_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_jscore_passthrough --storageEngine=wiredTiger

- name: replica_sets_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: replica_sets_jscore_passthrough
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- <<: *task_template
  name: replica_sets_multi_stmt_txn_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_multi_stmt_txn_jscore_passthrough --storageEngine=wiredTiger

- name: replica_sets_multi_stmt_txn_stepdown_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: replica_sets_multi_stmt_txn_stepdown_jscore_passthrough
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 15

- <<: *task_template
  name: replica_sets_multi_stmt_txn_kill_primary_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_multi_stmt_txn_kill_primary_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_multi_stmt_txn_terminate_primary_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_multi_stmt_txn_terminate_primary_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_initsync_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_initsync_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_initsync_static_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_initsync_static_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_kill_primary_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_kill_primary_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_terminate_primary_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_terminate_primary_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: replica_sets_kill_secondaries_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets_kill_secondaries_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: mongosTest
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=mongos_test

- <<: *task_template
  name: multiversion_auth
  commands:
  - func: "do setup"
  - func: "do multiversion setup"
  - func: "run tests"
    vars:
      task_path_suffix: /data/multiversion
      resmoke_args: --suites=multiversion_auth --storageEngine=wiredTiger

- <<: *task_template
  name: multiversion
  commands:
  - func: "do setup"
  - func: "do multiversion setup"
  - func: "run tests"
    vars:
      task_path_suffix: /data/multiversion
      resmoke_args: --suites=multiversion --storageEngine=wiredTiger

- name: noPassthrough_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: noPassthrough
      suite: no_passthrough
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 11

- name: noPassthroughWithMongod_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: noPassthroughWithMongod
      suite: no_passthrough_with_mongod
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 5

- <<: *task_template
  name: bulk_gle_passthrough
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=bulk_gle_passthrough --storageEngine=wiredTiger

- name: slow1_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: slow1
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 4
      resmoke_jobs_max: 1

- <<: *task_template
  name: serial_run
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=serial_run --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: sharded_collections_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharded_collections_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: sharding_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharding_jscore_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: sharding_jscore_op_query_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharding_jscore_op_query_passthrough --storageEngine=wiredTiger

- name: sharding_jscore_passthrough_wire_ops_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_jscore_passthrough_wire_ops
      suite: sharding_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger --shellReadMode=legacy --shellWriteMode=compatibility --excludeWithAnyTags=requires_find_command
      fallback_num_sub_suites: 4

- <<: *task_template
  name: sharded_multi_stmt_txn_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sharded_multi_stmt_txn_jscore_passthrough --storageEngine=wiredTiger

- name: multi_shard_multi_stmt_txn_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: multi_shard_multi_stmt_txn_jscore_passthrough
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 28
      resmoke_jobs_max: 0  # No cap on number of jobs.

- name: multi_shard_local_read_write_multi_stmt_txn_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: multi_shard_local_read_write_multi_stmt_txn_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 4

- name: multi_stmt_txn_jscore_passthrough_with_migration_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: multi_stmt_txn_jscore_passthrough_with_migration
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 19

- name: parallel_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: parallel
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1
      resmoke_jobs_max: 1

- <<: *task_template
  name: parallel_compatibility
  depends_on:
  - name: jsCore_compatibility
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=parallel --shellReadMode=legacy --shellWriteMode=compatibility --storageEngine=wiredTiger --excludeWithAnyTags=requires_find_command
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_replication
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_replication --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_replication_causal_consistency
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_replication_causal_consistency --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_replication_multi_stmt_txn
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_replication_multi_stmt_txn --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_replication_ubsan
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_replication_ubsan --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_replication_causal_consistency_ubsan
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_replication_causal_consistency_ubsan --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_replication_multi_stmt_txn_ubsan
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_replication_multi_stmt_txn_ubsan --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_with_balancer
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication_with_balancer --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_no_txns
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication --excludeWithAnyTags=uses_transactions --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_no_txns_with_balancer
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication_with_balancer --excludeWithAnyTags=uses_transactions --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- name: concurrency_sharded_causal_consistency_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: concurrency_sharded_causal_consistency
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 3
      use_large_distro: "true"
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_causal_consistency_and_balancer
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_causal_consistency_and_balancer --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_with_stepdowns
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_with_stepdowns --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_with_stepdowns_and_balancer
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_with_stepdowns_and_balancer --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_multi_stmt_txn
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication_multi_stmt_txn --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_multi_stmt_txn_with_balancer
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication_multi_stmt_txn_with_balancer --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_local_read_write_multi_stmt_txn
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication_local_read_write_multi_stmt_txn --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_sharded_replication_local_read_write_multi_stmt_txn_with_balancer
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_sharded_replication_local_read_write_multi_stmt_txn_with_balancer --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_simultaneous
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_simultaneous --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: concurrency_simultaneous_replication
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=concurrency_simultaneous_replication --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: read_concern_linearizable_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=read_concern_linearizable_passthrough --storageEngine=wiredTiger

- name: read_concern_majority_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: read_concern_majority_passthrough
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- <<: *task_template
  name: write_concern_majority_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=write_concern_majority_passthrough --storageEngine=wiredTiger

- name: secondary_reads_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: secondary_reads_passthrough
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 11

- <<: *task_template
  name: replica_sets
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=replica_sets --storageEngine=wiredTiger

- name: replica_sets_ese_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: replica_sets_ese
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- name: replica_sets_auth_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: replica_sets_auth
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- <<: *task_template
  name: sasl
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=sasl --storageEngine=wiredTiger

- name: sharding_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 15

- name: sharding_csrs_continuous_config_stepdown_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_csrs_continuous_config_stepdown
      suite: sharding_continuous_config_stepdown
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 22

- name: sharding_ese_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_ese
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 21

- name: sharding_op_query_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_op_query
      suite: sharding
      use_large_distro: "true"
      resmoke_args: --shellReadMode=legacy --storageEngine=wiredTiger --excludeWithAnyTags=requires_find_command
      fallback_num_sub_suites: 12

- name: sharding_auth_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_auth
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 20

- name: sharding_auth_audit_gen
  depends_on:
  - name: sharding_auth_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_auth_audit
      depends_on: sharding_auth
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 20

- name: sharding_last_stable_mongos_and_mixed_shards_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharding_last_stable_mongos_and_mixed_shards
      use_large_distro: "true"
      use_multiversion: /data/multiversion
      resmoke_args: ""
      fallback_num_sub_suites: 12

- <<: *task_template
  name: snmp
  commands:
  - func: "do setup"
  - func: "do snmp setup"
  - func: "run tests"
    vars:
      snmp_config_path: SNMPCONFPATH=snmpconf
      resmoke_args: --suites=snmp --storageEngine=wiredTiger

- name: ssl_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: ssl
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 5

- name: sslSpecial_gen
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sslSpecial
      suite: ssl_special
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 3

- <<: *task_template
  name: tool
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=tool --storageEngine=wiredTiger

- <<: *task_template
  name: jsCore_decimal
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=decimal --storageEngine=wiredTiger

- <<: *task_template
  name: read_only
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=read_only --storageEngine=wiredTiger

- <<: *task_template
  name: read_only_sharded
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=read_only_sharded --storageEngine=wiredTiger

- <<: *task_template
  name: session_jscore_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=session_jscore_passthrough --storageEngine=wiredTiger

- name: causally_consistent_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: causally_consistent_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 6

- name: causally_consistent_jscore_passthrough_auth_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: causally_consistent_jscore_passthrough_auth
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- name: sharded_causally_consistent_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: sharded_causally_consistent_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 6

- name: retryable_writes_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: retryable_writes_jscore_passthrough
      depends_on: jsCore
      use_large_distro: "true"
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 8

- name: logical_session_cache_replication_default_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_replication_default_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- name: logical_session_cache_replication_100ms_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_replication_100ms_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 8

- name: logical_session_cache_replication_1sec_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_replication_1sec_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- name: logical_session_cache_replication_10sec_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_replication_10sec_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 7

- name: logical_session_cache_sharding_default_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_sharding_default_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- name: logical_session_cache_sharding_100ms_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_sharding_100ms_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- name: logical_session_cache_sharding_1sec_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_sharding_1sec_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 3

- name: logical_session_cache_sharding_10sec_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_sharding_10sec_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- name: logical_session_cache_standalone_default_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_standalone_default_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- name: logical_session_cache_standalone_100ms_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_standalone_100ms_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- name: logical_session_cache_standalone_1sec_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_standalone_1sec_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 3

- name: logical_session_cache_standalone_10sec_refresh_jscore_passthrough_gen
  depends_on:
  - name: jsCore
  commands:
  - func: "generate resmoke tasks"
    vars:
      task: logical_session_cache_standalone_10sec_refresh_jscore_passthrough
      depends_on: jsCore
      resmoke_args: --storageEngine=wiredTiger
      fallback_num_sub_suites: 1

- <<: *task_template
  name: retryable_writes_jscore_stepdown_passthrough
  depends_on:
  - name: jsCore
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=retryable_writes_jscore_stepdown_passthrough --storageEngine=wiredTiger

- <<: *task_template
  name: watchdog_wiredtiger
  commands:
  - func: "do setup"
  - func: "do watchdog setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=watchdog --storageEngine=wiredTiger
      resmoke_jobs_max: 1

# This is a separate task because it is only supported on Ubuntu 16.04+ which are not inmemory builders
- <<: *task_template
  name: watchdog_inmemory
  commands:
  - func: "do setup"
  - func: "do watchdog setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=watchdog --storageEngine=inMemory
      resmoke_jobs_max: 1

- <<: *task_template
  name: free_monitoring
  commands:
  - func: "do setup"
  - command: shell.exec
    type: test
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose

        ${activate_virtualenv}
        # Since the free monitoring tests use python 3 via C exec,
        # they deliberately hit python3.6 on Windows and toolchain python otherwise.
        # We happen to pre-seed the core requirements in the toolchain,
        # but we have no way of doing so to Windows python3.6 installed via Chocolatey.
        if command -V cygpath; then
            echo "Installing core requirements into Python at '${python3}'"
            "$(cygpath "${python3}")" -mpip install -r etc/pip/core-requirements.txt
        fi
  - func: "run tests"
    vars:
      resmoke_args: --suites=free_monitoring --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: fle
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=fle --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- <<: *task_template
  name: jsonSchema
  commands:
  - func: "do setup"
  - func: "run tests"
    vars:
      resmoke_args: --suites=json_schema --storageEngine=wiredTiger
      resmoke_jobs_max: 1

- name: powercycle
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      mongod_extra_options: --mongodOptions=\"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}' --storageEngine wiredTiger\"

- name: powercycle_kill_mongod
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      crash_options: --crashMethod=kill --crashWaitTime=45 --jitterForCrashWaitTime=5 --instanceId=${instance_id}
      mongod_extra_options: --mongodOptions=\"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}' --storageEngine wiredTiger\"

- name: powercycle_fcv4.0
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      client_options: --numCrudClients=20 --numFsmClients=20
      mongod_options: --mongodUsablePorts ${standard_port} ${secret_port} --dbPath=${db_path} --logPath=${log_path} --fcv=4.0
      mongod_extra_options: --mongodOptions=\"--setParameter enableTestCommands=1  --setParameter logComponentVerbosity='{storage:{recovery:2}}' --storageEngine wiredTiger\"

- name: powercycle_replication
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      mongod_extra_options: --replSet=powercycle --mongodOptions=\"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}' --storageEngine wiredTiger\"

- name: powercycle_replication_smalloplog
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      mongod_extra_options: --replSet=powercycle --mongodOptions=\"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}' --oplogSize 20 --storageEngine wiredTiger\"

- name: powercycle_syncdelay
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      mongod_extra_options: --mongodOptions=\"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}' --syncdelay 10 --storageEngine wiredTiger\"

- name: powercycle_write_concern_majority
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      client_options: "--numCrudClients=20 --numFsmClients=20 --writeConcern='{\"w\": \"majority\"}'"
      mongod_extra_options: --mongodOptions \"--setParameter enableTestCommands=1 --setParameter logComponentVerbosity='{storage:{recovery:2}}' --storageEngine wiredTiger\"

- name: powercycle_mobile
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "set up remote credentials"
    vars:
      <<: *powercycle_remote_credentials
  - func: "set up EC2 instance"
    vars:
      <<: *powercycle_ec2_instance
  - command: expansions.update
    <<: *powercycle_expansions
  - func: "run powercycle test"
    timeout_secs: 1800 # 30 minute timeout for no output
    vars:
      <<: *powercycle_test
      # We do 5 rather than 15 loops when running against the mobile storage engine because
      # collection validation otherwise starts to take several minutes after each loop.
      client_options: --testLoops=5 --numCrudClients=20 --numFsmClients=20
      mongod_extra_options: --mongodOptions=\"--setParameter enableTestCommands=1 --storageEngine mobile\"

- name: idl_tests
  depends_on:
  - name: compile
  commands:
  - func: "do setup"
  - func: "run idl tests"

- name: buildscripts_test
  depends_on: []
  commands:
  - func: "git get project"
  - func: "get buildnumber"
  - func: "set up credentials"
  - func: "run tests"
    vars:
      resmoke_args: --suites=buildscripts_test
      resmoke_jobs_max: 1

- name: package
  depends_on:
  - name: compile
  commands:
    - func: "fetch artifacts"
    - func: "set up remote credentials"
      vars:
        private_key_file: ~/.ssh/kitchen.pem
        private_key_remote: ${kitchen_private_key}
        aws_key_remote: ${kitchen_aws_key}
        aws_secret_remote: ${kitchen_aws_secret}
    - func: "run kitchen"

- name: publish_packages
  # This should prevent this task from running in patch builds, where we
  # don't want to publish packages.
  patchable: false
  stepback: false
  # Same dependencies as "push" below
  depends_on:
  - name: compile
  - name: jsCore
  - name: dbtest
  - name: replica_sets_jscore_passthrough
  commands:
    - func: "fetch artifacts"
    - func: "apply compile expansions"
    - func: "set up remote credentials"
      vars:
        aws_key_remote: ${repo_aws_key}
        aws_secret_remote: ${repo_aws_secret}
    - func: "set up notary client credentials"
    - command: shell.exec
      params:
        working_dir: src
        script: |
          . ./notary_env.sh

          set -o errexit
          set -o verbose

          CURATOR_RELEASE=${curator_release|"latest"}
          curl -L -O http://boxes.10gen.com/build/curator/curator-dist-rhel70-$CURATOR_RELEASE.tar.gz
          tar -zxvf curator-dist-rhel70-$CURATOR_RELEASE.tar.gz
          ./curator repo --config ./etc/repo_config.yaml --distro ${packager_distro} --edition ${repo_edition} --version ${version} --arch ${packager_arch} --packages repo

- name: push
  patchable: false
  depends_on:
  - name: jsCore
  - name: dbtest
  - name: replica_sets_jscore_passthrough
  stepback: false
  commands:
    - func: "fetch artifacts"
    - func: "fetch binaries"
    # Fetch the shell
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${mongo_shell}
        bucket: mciuploads
        local_file: src/mongo-shell.tgz
    # Fetch the sources (on relevant variants only)
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: ${project}/${build_variant}/${revision}/sources/mongo-src-${build_id}.${ext|tgz}
        bucket: mciuploads
        local_file: src/distsrc.${ext|tgz}
        build_variants: [ rhel70, windows-64-2k8-ssl ]
    - func: "apply compile expansions"
    - func: "fetch debugsymbols archive"
    - func: "set up remote credentials"
      vars:
        aws_key_remote: ${repo_aws_key}
        aws_secret_remote: ${repo_aws_secret}
    - func: "set up notary client credentials"
    - command: shell.exec
      params:
        working_dir: src
        script: |
          . ./notary_env.sh

          set -o errexit
          set -o verbose

          mv mongo-binaries.tgz mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}
          mv mongo-shell.tgz mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}
          mv mongo-debugsymbols.tgz mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz} || true
          mv distsrc.${ext|tgz} mongodb-src-${src_suffix}.${ext|tar.gz} || true
          /usr/bin/find build/ -type f | grep msi$ | xargs -I original_filename cp original_filename mongodb-win32-${push_arch}-${suffix}.msi || true

          /usr/local/bin/notary-client.py --key-name "server-4.2" --auth-token-file ${workdir}/src/signing_auth_token --comment "Evergreen Automatic Signing ${revision} - ${build_variant} - ${branch_name}" --notary-url http://notary-service.build.10gen.cc:5000 --skip-missing mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz} mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz} mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz} mongodb-win32-${push_arch}-${suffix}.msi mongodb-src-${src_suffix}.${ext|tar.gz}

    # Put the binaries tarball/zipfile
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}
    # Put the shell tarball/zipfile
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}
    # Put the source tarball
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-src-${src_suffix}.${ext|tar.gz}
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}
        build_variants: [ rhel70, windows-64-2k8-ssl ]

    # Put the debug symbols
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        aws_key: ${aws_key}
        permissions: public-read
        local_file: src/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}
        bucket: build-push-testing
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}
        optional: true

    # Put the binaries tarball signature
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sig
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sig

    # Put the shell tarball signature
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sig
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sig

    # Put the source tarball signature
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-src-${src_suffix}.${ext|tar.gz}.sig
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.sig
        build_variants: [ rhel70, windows-64-2k8-ssl ]

    # Put the debug symbols signature
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        aws_key: ${aws_key}
        permissions: public-read
        local_file: src/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.sig
        bucket: build-push-testing
        content_type: ${content_type|application/gzip}
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.sig
        optional: true

    # Put the signed MSI file
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        permissions: public-read
        build_variants: ["enterprise-windows-64-2k8", "windows-64-2k8-ssl"]
        local_file: src/mongodb-win32-${push_arch}-${suffix}-signed.msi
        bucket: build-push-testing
        content_type: application/x-msi
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi

    # Put the binaries tarball sha1
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha1
        aws_key: ${aws_key}
        permissions: public-read
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha1

    # Put the shell tarball sha1
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha1
        aws_key: ${aws_key}
        permissions: public-read
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha1

    # Put the source tarball sha1
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-src-${src_suffix}.${ext|tar.gz}.sha1
        aws_key: ${aws_key}
        permissions: public-read
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.sha1
        build_variants: [ rhel70, windows-64-2k8-ssl ]

    # Put the debug symbols sha1
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        aws_key: ${aws_key}
        permissions: public-read
        local_file: src/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.sha1
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.sha1
        optional: true

    # Push the signed MSI sha1
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        permissions: public-read
        build_variants: ["enterprise-windows-64-2k8", "windows-64-2k8-ssl"]
        local_file: src/mongodb-win32-${push_arch}-${suffix}-signed.msi.sha1
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi.sha1

    # Put the binaries tarball sha256
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha256
        permissions: public-read
        aws_key: ${aws_key}
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha256

    # Put the shell tarball sha256
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha256
        permissions: public-read
        aws_key: ${aws_key}
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha256

    # Put the source tarball sha256
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-src-${src_suffix}.${ext|tar.gz}.sha256
        permissions: public-read
        aws_key: ${aws_key}
        bucket: build-push-testing
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.sha256
        build_variants: [ rhel70, windows-64-2k8-ssl ]

    # Put the debug symbols sha256
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.sha256
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.sha256
        optional: true

    # Put the signed MSI sha256
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        build_variants: ["enterprise-windows-64-2k8", "windows-64-2k8-ssl"]
        local_file: src/mongodb-win32-${push_arch}-${suffix}-signed.msi.sha256
        bucket: build-push-testing
        permissions: public-read
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi.sha256
        content_type: text/plain

    # Put the binaries tarball md5
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.md5
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.md5

    # Put the shell tarball md5
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.md5
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.md5

    # Put the source tarball md5
    - command: s3.put
      params:
        aws_secret: ${aws_secret}
        local_file: src/mongodb-src-${src_suffix}.${ext|tar.gz}.md5
        aws_key: ${aws_key}
        bucket: build-push-testing
        permissions: public-read
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.md5
        build_variants: [ rhel70, windows-64-2k8-ssl ]

    # Put the debug symbols md5
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.md5
        bucket: build-push-testing
        content_type: text/plain
        permissions: public-read
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.md5
        optional: true

    # Put the signed MSI md5
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        build_variants: ["enterprise-windows-64-2k8", "windows-64-2k8-ssl"]
        local_file: src/mongodb-win32-${push_arch}-${suffix}-signed.msi.md5
        bucket: build-push-testing
        permissions: public-read
        content_type: text/plain
        remote_file: ${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi.md5

    - command: s3Copy.copy
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        s3_copy_files:
            #Binaries
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}', 'bucket': '${push_bucket}'}}

            #Shell
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}', 'bucket': '${push_bucket}'}}

            #Source tarball
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}', 'bucket': 'build-push-testing'},
               'destination': {'path': 'src/mongodb-src-${src_suffix}.${ext|tar.gz}', 'bucket': '${push_bucket}'},
               'build_variants': [ 'rhel70', 'windows-64-2k8-ssl' ]}

            #MSI (Windows only)
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-win32-${push_arch}-${suffix}-signed.msi', 'bucket': '${push_bucket}'},
               'build_variants': [ 'enterprise-windows-64-2k8', 'windows-64-2k8-ssl' ]}

            #Binaries Signature
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sig', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sig', 'bucket': '${push_bucket}'}}

            #Shell Signature
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sig', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sig', 'bucket': '${push_bucket}'}}

            #Source tarball signature
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.sig', 'bucket': 'build-push-testing'},
               'destination': {'path': 'src/mongodb-src-${src_suffix}.${ext|tar.gz}.sig', 'bucket': '${push_bucket}'},
               'build_variants': [ 'rhel70', 'windows-64-2k8-ssl' ]}

            #SHA1 for binaries
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha1', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha1', 'bucket': '${push_bucket}'}}

            #SHA1 for shell
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha1', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha1', 'bucket': '${push_bucket}'}}

            #SHA1 for source tarball
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.sha1', 'bucket': 'build-push-testing'},
               'destination': {'path': 'src/mongodb-src-${src_suffix}.${ext|tar.gz}.sha1', 'bucket': '${push_bucket}'},
               'build_variants': [ 'rhel70', 'windows-64-2k8-ssl' ]}

            #SHA1 for MSI
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi.sha1', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-win32-${push_arch}-${suffix}-signed.msi.sha1', 'bucket': '${push_bucket}'},
               'build_variants': ['enterprise-windows-64-2k8', 'windows-64-2k8-ssl']}

            #SHA256 for binaries
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha256', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha256', 'bucket': '${push_bucket}'}}

            #SHA256 for shell
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.sha256', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.sha256', 'bucket': '${push_bucket}'}}

            #SHA256 for source tarball
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.sha256', 'bucket': 'build-push-testing'},
               'destination': {'path': 'src/mongodb-src-${src_suffix}.${ext|tar.gz}.sha256', 'bucket': '${push_bucket}'},
               'build_variants': [ 'rhel70', 'windows-64-2k8-ssl' ]}

            #SHA256 for MSI files
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi.sha256', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-win32-${push_arch}-${suffix}-signed.msi.sha256', 'bucket': '${push_bucket}'},
               'build_variants': ['enterprise-windows-64-2k8', 'windows-64-2k8-ssl']}

            #MD5 for binaries
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.md5', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}.md5', 'bucket': '${push_bucket}'}}

            #MD5 for shell
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-shell-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}.md5', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-shell-${push_name}-${push_arch}-${suffix}.${ext|tgz}.md5', 'bucket': '${push_bucket}'}}

            #MD5 for source tarball
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-src-${src_suffix}-${task_id}.${ext|tar.gz}.md5', 'bucket': 'build-push-testing'},
               'destination': {'path': 'src/mongodb-src-${src_suffix}.${ext|tar.gz}.md5', 'bucket': '${push_bucket}'},
               'build_variants': [ 'rhel70', 'windows-64-2k8-ssl' ]}

            #MD5 for MSIs
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-win32-${push_arch}-${suffix}-${task_id}-signed.msi.md5', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-win32-${push_arch}-${suffix}-signed.msi.md5', 'bucket': '${push_bucket}'},
               'build_variants': ['enterprise-windows-64-2k8', 'windows-64-2k8-ssl'], }

    # Debug symbols are not created for all variants and the copy is optional.
    - command: s3Copy.copy
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        optional: true
        s3_copy_files:
            #Debug Symbols
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}', 'bucket': '${push_bucket}'}}

            #Debug Symbols Signature
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.sig', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.sig', 'bucket': '${push_bucket}'}}

            #SHA1 for debug symbols
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.sha1', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.sha1', 'bucket': '${push_bucket}'}}

            #SHA256 for debugsymbols
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.sha256', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.sha256', 'bucket': '${push_bucket}'}}

            #MD5 for debugsymbols
            - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}-${task_id}.${ext|tgz}.md5', 'bucket': 'build-push-testing'},
               'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-debugsymbols-${suffix}.${ext|tgz}.md5', 'bucket': '${push_bucket}'}}

- name: fetch_test_lifecycle
  depends_on: []
  commands:
  - func: "git get project"
  - func: "fetch test_lifecycle.yml"
    vars:
      # This task is meant to fail if there is an error while fetching test_lifecycle.yml since
      # the compile task won't fail.
      fail_task_on_error: true

- name: update_test_lifecycle
  exec_timeout_secs: 21600 # 6 hour timeout for the task overall
  depends_on: []
  commands:
  - func: "git get project"
  - func: "configure evergreen api credentials"
  - command: shell.exec
    timeout_secs: 14400 # Timeout if there is no output for 4 hours
    type: test
    params:
      working_dir: src
      silent: true
      script: |
        set -o errexit

        # Set up the git ssh private key
        mkdir -p ~/.ssh
        echo -n "${testlifecycle_ssh_key}" > ~/.ssh/test_lifecycle.pem
        chmod 0600 ~/.ssh/test_lifecycle.pem
        export GIT_SSH_COMMAND="ssh -i ~/.ssh/test_lifecycle.pem"

        # Create the jira credentials configuration file
        cat > .jira.yml <<END_OF_CREDS
        server: "https://jira.mongodb.org"
        access_token: "${testlifecycle_jira_access_token}"
        access_token_secret: "${testlifecycle_jira_access_token_secret}"
        consumer_key: "${testlifecycle_jira_consumer_key}"
        key_cert: |
        $(echo "${testlifecycle_jira_key_certificate}" | sed  's/^/  /')
        END_OF_CREDS

        set -o verbose

        ${activate_virtualenv}
        python2 -m pip install -r etc/pip/jira-requirements.txt

        # We use a small batch size to avoid hitting the load balancer timeout if the Evergreen
        # API query is not fast enough.
        # Evergreen executable is in $HOME.
        PATH=$PATH:$HOME $python buildscripts/update_test_lifecycle.py  \
            --project ${project}                                        \
            --requestBatchSize 20                                       \
            --commit                                                    \
            --resmokeTagFile "etc/test_lifecycle.yml"                   \
            --metadataRepo "git@github.com:mongodb/mongo-test-metadata" \
            --referencesFile "references.yml"                           \
            --gitUserName "Test Lifecycle"                              \
            --gitUserEmail "build+testlifecycle@mongodb.com"            \
            --jiraConfig .jira.yml

- name: shared_scons_cache_pruning
  exec_timeout_secs: 7200 # 2 hour timeout for the task overall
  depends_on: []
  commands:
  - func: "git get project"
  - func: "shared scons cache pruning"

#######################################
#             Task Groups             #
#######################################
task_groups:
- <<: *compile_task_group_template
  name: compile_TG
  tasks:
  - compile
- <<: *compile_task_group_template
  name: dbtest_TG
  tasks:
  - compile_dbtest
  - dbtest
- <<: *compile_task_group_template
  name: compile_all_run_unittests_TG
  tasks:
  - compile
  - compile_unittests
  - unittests
  - compile_dbtest
  - dbtest
  - compile_all
- name: embedded_sdk_build_and_test
  setup_group:
    - command: manifest.load
    - func: "git get project"
    - func: "get buildnumber"
    - func: "set up credentials"
    - func: "setup android toolchain" # noop if ${setup_android_toolchain} is not "true"
    - func: "install pip requirements"
    - func: "generate compile expansions"
  teardown_group:
    - func: "scons cache pruning"
    - func: "umount shared scons directory"
  setup_task:
    - func: "set up virtualenv"
    - func: "set task expansion macros"
    - func: "apply compile expansions"
  teardown_task:
  tasks:
  - "embedded_sdk_build_cdriver"
  - "embedded_sdk_install_dev"
  - "embedded_sdk_s3_put"
  - "embedded_sdk_install_tests"
  - "embedded_sdk_tests_s3_put"
  - "embedded_sdk_run_tests"
  - "embedded_sdk_s3_put_latest"
  - "embedded_sdk_tests_s3_put_latest"
- <<: *stitch_support_task_group_template
  name: stitch_support_lib_build_and_archive
  tasks:
    - "stitch_support_create_lib"
- <<: *stitch_support_task_group_template
  name: stitch_support_lib_build_and_test
  tasks:
    - "stitch_support_install_tests"
    - "stitch_support_run_tests"

#######################################
#               Modules               #
#######################################
# if a module is added and to be added to the manifest
# be sure to add the module to git.get_project revisions parameter
modules:
- name: enterprise
  repo: git@github.com:10gen/mongo-enterprise-modules.git
  prefix: src/mongo/db/modules
  branch: master

- name: wtdevelop
  repo: git@github.com:wiredtiger/wiredtiger.git
  prefix: src/third_party
  branch: develop

#######################################
#            Buildvariants            #
#######################################

buildvariants:

- name: enterprise-windows-64-2k8
  display_name: "! Enterprise Windows 2008R2"
  modules:
  - enterprise
  run_on:
  - windows-64-vs2017-test
  expansions:
    platform_decompress: unzip
    exe: ".exe"
    push_path: win32
    push_bucket: downloads.10gen.com
    push_name: win32
    push_arch: x86_64-enterprise-windows-64
    msi_target: msi
    content_type: application/zip
    compile_flags: --release --ssl MONGO_DISTMOD=windows-64 CPPPATH="c:/sasl/include c:/snmp/include" LIBPATH="c:/sasl/lib c:/snmp/lib" -j$(( $(grep -c ^processor /proc/cpuinfo) / 2 )) --dynamic-windows --win-version-min=ws08r2
    # We invoke SCons using --jobs = (# of CPUs / 4) to avoid causing out of memory errors due to
    # spawning a large number of linker processes.
    num_scons_link_jobs_available: $(( $(grep -c ^processor /proc/cpuinfo) / 4 ))
    python: python
    python3: '/cygdrive/c/python/python36/python.exe'
    ext: zip
    use_scons_cache: true
    multiversion_platform: windows
    multiversion_edition: enterprise
    tooltags: "ssl sasl"
    build_mongoreplay: false
    jstestfuzz_num_generated_files: 35
    target_resmoke_time: 20
    large_distro_name: windows-64-vs2017-compile
  display_tasks:
  - *dbtest
  tasks:
  - name: compile_TG
    requires:
    - name: burn_in_tests
    - name: verify_pip
    distros:
    - windows-64-vs2017-compile
  - name: compile_benchmarks
    distros:
    - windows-64-vs2017-compile
  - name: burn_in_tests
